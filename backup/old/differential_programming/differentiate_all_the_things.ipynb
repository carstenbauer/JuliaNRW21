{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "] activate ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "push!(LOAD_PATH, joinpath(pwd(), \"../../\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differentiate through an ODE solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using OrdinaryDiffEq\n",
    "\n",
    "function lotka_volterra(du,u,p,t)\n",
    "  x, y = u\n",
    "  α, β, δ, γ = p\n",
    "  du[1] = dx = α*x - β*x*y\n",
    "  du[2] = dy = -δ*y + γ*x*y\n",
    "end\n",
    "\n",
    "u0 = [1.0,1.0]\n",
    "tspan = (0.0,10.0)\n",
    "p = [1.5,1.0,3.0,1.0]\n",
    "prob = ODEProblem(lotka_volterra,u0,tspan,p)\n",
    "sol = solve(prob,Tsit5())\n",
    "\n",
    "using Plots\n",
    "plot(sol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, DiffEqFlux\n",
    "p = [2.2, 1.0, 2.0, 0.4] # Initial Parameter Vector\n",
    "\n",
    "function predict_adjoint() # Our 1-layer neural network\n",
    "  Array(concrete_solve(prob,Tsit5(),u0,p,saveat=0.0:0.1:10.0))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we choose a loss function. Our goal will be to find parameter that make the Lotka-Volterra solution constant $x(t)=1$, so we defined our loss as the squared distance from 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_adjoint() = sum(abs2,x-1 for x in predict_adjoint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux: throttle\n",
    "data = Iterators.repeated((), 100)\n",
    "opt = ADAM(0.1)\n",
    "cb = function () #callback function to observe training\n",
    "    if (@isdefined IJulia)\n",
    "        # \"animation\" in jupyter\n",
    "        IJulia.clear_output(true)\n",
    "    end\n",
    "    display(loss_adjoint())\n",
    "    # using `remake` to re-create our `prob` with current parameters `p`\n",
    "    display(plot(solve(remake(prob,p=p),Tsit5(),saveat=0.0:0.1:10.0),ylim=(0,6)))\n",
    "end\n",
    "\n",
    "# Display the ODE with the initial parameter values.\n",
    "cb()\n",
    "\n",
    "Flux.train!(loss_adjoint, Flux.params(p), data, opt, cb = throttle(cb, .1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even cooler trebuchet example: https://fluxml.ai/2019/03/05/dp-vs-rl.html"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "33ac9058187c479f86fcefaaa3a78d83",
   "lastKernelId": "a0f1e300-8f8c-4645-9945-3b7fccc7777c"
  },
  "kernelspec": {
   "display_name": "Julia 1.3.1",
   "language": "julia",
   "name": "julia-1.3"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
