{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multithreading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia starts with a single thread. We must tell it explicitly to start multiple threads.\n",
    "\n",
    "#### Environmental variable\n",
    "\n",
    "On Linux/MacOS:\n",
    "\n",
    "```bash\n",
    "export JULIA_NUM_THREADS=4\n",
    "```\n",
    "\n",
    "On Windows:\n",
    "\n",
    "```bash\n",
    "set JULIA_NUM_THREADS=4\n",
    "```\n",
    "\n",
    "Afterwards start julia.\n",
    "\n",
    "#### Command line argument\n",
    "\n",
    "```bash\n",
    "julia -t 4\n",
    "```\n",
    "\n",
    "or\n",
    "\n",
    "```bash\n",
    "julia --threads 4\n",
    "```\n",
    "\n",
    "#### Jupyter kernel\n",
    "\n",
    "You can also create a *Jupyter kernel* for multithreaded Julia:\n",
    "\n",
    "```julia\n",
    "using IJulia\n",
    "installkernel(\"Julia (4 threads)\", env=Dict(\"JULIA_NUM_THREADS\"=>\"4\"))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can readily check how many threads we are running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, in contrast to our distributed computing discussion, we will only consider only a single process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Distributed: nprocs\n",
    "\n",
    "nprocs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Threads.@spawn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Threads.@spawn` macro is very similar to the `Distributed.@spawn` macro. However, instead of spawning tasks on different worker processes (potentially on different machines) it spawns tasks on different threads. Basically, it creates (and immediately returns) a `Task` and puts it onto a todo-list. The scheduler will then dynamically assign these tasks to threads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import everything we need from `Base.Threads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base.Threads: @spawn, nthreads, threadid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x0000000128e6df90"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    }
   ],
   "source": [
    "@spawn println(\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While `Threads.@spawn` returns the task right away, we might have to wait until the task is done and then fetch our result (again, just as for `Distributed.@spawn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.994932 seconds (95 allocations: 2.906 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = @spawn begin sleep(3); return 4 end # returns right away\n",
    "@time fetch(t) # we need to wait until the task is done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we can use (some of) the control flow tools that we've already seen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.000001 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@sync t = @spawn begin sleep(3); return 4 end # only returns the task once it is done\n",
    "@time fetch(t) # no need to wait, the task is already done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we can spawn many tasks in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm 2\n",
      "Hi, I'm 5\n",
      "Hi, I'm 2\n",
      "Hi, I'm 3\n",
      "Hi, I'm 4\n",
      "Hi, I'm 2\n",
      "Hi, I'm 6\n",
      "Hi, I'm 2\n",
      "Hi, I'm 2\n",
      "Hi, I'm 1\n",
      "Hi, I'm 1\n",
      "Hi, I'm 1\n"
     ]
    }
   ],
   "source": [
    "for i in 1:2*nthreads()\n",
    "    @spawn println(\"Hi, I'm \", threadid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the tasks are **dynamically scheduled**. Some threads do more work (more values of i) than others!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `@threads`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Roughly speaking, the macro `Threads.@threads` is for multithreading (threads) what `Distributed.@distributed` was for distributed computing (processes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base.Threads: @threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi, I'm 1\n",
      "Hi, I'm 5\n",
      "Hi, I'm 4\n",
      "Hi, I'm 5\n",
      "Hi, I'm 3\n",
      "Hi, I'm 4\n",
      "Hi, I'm 6\n",
      "Hi, I'm 2\n",
      "Hi, I'm 3\n",
      "Hi, I'm 6\n",
      "Hi, I'm 2\n",
      "Hi, I'm 1\n"
     ]
    }
   ],
   "source": [
    "@threads for i in 1:2*nthreads()\n",
    "    println(\"Hi, I'm \", threadid())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast to `@spawn` above, `@threads` is **statically scheduled**. The iteration range of the for loop is divided equally between the threads. Every thread handles precisely two iterations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In a future version of Julia, there will likely be other scheduling policies, for example a `:dynamic` similar to the behavior of `@spawn`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @threads :static for i in 1:2*nthreads()\n",
    "#     println(\"Hi, I'm \", threadid())\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where is my `pmap` pendant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, it doesn't exist. But, conceptually, we can implement it as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tmap (generic function with 1 method)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmap(fn, itr) = map(fetch, map(i -> Threads.@spawn(fn(i)), itr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 (2)\n",
      "9 (4)\n",
      "5 (6)\n",
      "6 (5)\n",
      "2 (3)\n",
      "10 (5)\n",
      "3 (2)\n",
      "8 (5)\n",
      "7 (5)\n",
      "4 (1)\n"
     ]
    }
   ],
   "source": [
    "tmap(i -> println(i, \" ($(threadid()))\"), 1:10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, however, that this implementation creates temporary allocations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `@threads` vs `@spawn`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `@threads`\n",
    "\n",
    "* rather lightweight, i.e. small overhead\n",
    "* **statically scheduled**\n",
    "* good for uniform workload\n",
    "\n",
    "#### `@spawn`\n",
    "\n",
    "* more overhead\n",
    "* **dynamically scheduled**\n",
    "* handles non-uniform workloads well\n",
    "* efficient nesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: filling an array in parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal ist to fill an array in parallel using `@threads` and `@spawn`, respectively.\n",
    "\n",
    "Note that while we had to use things like `SharedArrays` in the case of distributed computing, threads share the same memory! We also don't have to use constructs like `@everywhere` since everything is running in the same julia process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Base.Threads: @threads, @spawn, nthreads, threadid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fill_array_threads (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_array_threads(a)\n",
    "    @threads for i in 1:length(a)\n",
    "        a[i] = threadid()\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zeros(nthreads()*10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60-element Array{Float64,1}:\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 1.0\n",
       " 2.0\n",
       " 2.0\n",
       " 2.0\n",
       " ⋮\n",
       " 5.0\n",
       " 5.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0\n",
       " 6.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_array_threads(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a version using `Threads.@spawn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fill_array_threads (generic function with 1 method)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_array_threads(a)\n",
    "    @sync for i in 1:length(a)\n",
    "        @spawn(a[i] = threadid())\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60-element Array{Float64,1}:\n",
       " 2.0\n",
       " 3.0\n",
       " 3.0\n",
       " 2.0\n",
       " 3.0\n",
       " 4.0\n",
       " 3.0\n",
       " 5.0\n",
       " 3.0\n",
       " 4.0\n",
       " 2.0\n",
       " 2.0\n",
       " 5.0\n",
       " ⋮\n",
       " 3.0\n",
       " 6.0\n",
       " 4.0\n",
       " 2.0\n",
       " 4.0\n",
       " 3.0\n",
       " 4.0\n",
       " 6.0\n",
       " 5.0\n",
       " 3.0\n",
       " 4.0\n",
       " 4.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = zeros(nthreads()*10);\n",
    "fill_array_threads(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark both variants!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  47.508 μs (376 allocations: 43.70 KiB)\n",
      "  2.906 ms (1300 allocations: 2.97 MiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@btime fill_array_threads(x) samples=10 setup=(x = zeros(nthreads()*10));\n",
    "@btime fill_array_spawn(x) samples=10 setup=(x = zeros(nthreads()*10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the `@threads` based implementation is much faster. However, this shouldn't be surprising, given that our tasks are lightweight and uniform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-uniform workload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fill_array_threads_nonuniform (generic function with 1 method)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_array_threads_nonuniform(a)\n",
    "    @threads for i in 1:length(a)\n",
    "        a[i] = norm(rand(i^3))\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = zeros(nthreads()*10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_array_threads_nonuniform(a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fill_array_spawn_nonuniform (generic function with 1 method)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_array_spawn_nonuniform(a)\n",
    "    @sync for i in 1:length(a)\n",
    "        Threads.@spawn(a[i] = norm(rand(i^3)))\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_array_spawn_nonuniform(a);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.214 ms (143 allocations: 25.56 MiB)\n",
      "  3.691 ms (545 allocations: 25.60 MiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@btime fill_array_threads_nonuniform(x) samples=10 setup=(x = zeros(nthreads()*10));\n",
    "@btime fill_array_spawn_nonuniform(x) samples=10 setup=(x = zeros(nthreads()*10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that compared to above, the result has flipped: the `@spawn` implementation, due to it's dynamic scheduling, is more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threads require more care: parallel summation (naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum (generic function with 1 method)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum(xs)\n",
    "    s = zero(eltype(xs))\n",
    "    for x in xs\n",
    "        s += x\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_threaded_naive (generic function with 1 method)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum_threaded_naive(xs)\n",
    "    s = zero(eltype(xs))\n",
    "    @threads for x in xs\n",
    "        s += x\n",
    "    end\n",
    "    return s\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = rand(100_000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(xs) = 49947.95658092538\n",
      "mysum(xs) = 49947.95658092537\n",
      "mysum_threaded_naive(xs) = 8712.984662727036\n"
     ]
    }
   ],
   "source": [
    "@show sum(xs);\n",
    "@show mysum(xs);\n",
    "@show mysum_threaded_naive(xs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel summation (divide the work)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_threaded (generic function with 1 method)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mysum_threaded(xs)\n",
    "    b = ceil(Int, length(xs)/nthreads())\n",
    "    map(sub_xs -> Threads.@spawn(sum(sub_xs)), Iterators.partition(xs, b)) .|> fetch |> sum\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function mysum_threaded_alternative(xs)\n",
    "#     b = ceil(Int, length(xs)/nthreads())\n",
    "#     tasks = [Threads.@spawn(sum(subx)) for subx in Iterators.partition(xs, b)]\n",
    "#     return sum(fetch(t) for t in tasks)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sum(xs) = 49947.95658092538\n",
      "mysum(xs) = 49947.95658092537\n",
      "mysum_threaded(xs) = 49947.95658092538\n",
      "mysum_threaded_loop(xs) = 49947.95658092538\n"
     ]
    }
   ],
   "source": [
    "@show sum(xs);\n",
    "@show mysum(xs);\n",
    "@show mysum_threaded(xs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  97.828 μs (0 allocations: 0 bytes)\n",
      "  6.685 μs (48 allocations: 4.76 KiB)\n",
      "  7.757 μs (48 allocations: 4.61 KiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@btime mysum($xs);\n",
    "@btime mysum_threaded($xs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel summation (atomics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mysum_threaded_atomics (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base.Threads: Atomic, atomic_add!\n",
    "\n",
    "function mysum_threaded_atomics(xs)\n",
    "    s = Atomic{eltype(xs)}(zero(eltype(xs)))\n",
    "    @threads for x in xs\n",
    "        atomic_add!(s, x)\n",
    "    end\n",
    "    return s[]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mysum(xs) = 50104.088123258254\n",
      "mysum_threaded_atomics(xs) = 50104.088123258334\n"
     ]
    }
   ],
   "source": [
    "@show mysum(xs);\n",
    "@show mysum_threaded_atomics(xs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  97.846 μs (1 allocation: 16 bytes)\n",
      "  4.821 ms (33 allocations: 4.19 KiB)\n",
      "  7.360 μs (48 allocations: 4.76 KiB)\n"
     ]
    }
   ],
   "source": [
    "@btime mysum(xs);\n",
    "@btime mysum_threaded_atomics(xs);\n",
    "@btime mysum_threaded(xs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [Atomic Operations](https://docs.julialang.org/en/v1/manual/parallel-computing/#Atomic-Operations-1) in the Julia doc for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spawning of tasks can also be nested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job2 (spawned from 2, processed by 2)\n",
      "job1 (spawned from 4, processed by 4)\n",
      "job3 (spawned from 4, processed by 5)\n",
      "job1 (spawned from 3, processed by 4)\n",
      "job1 (spawned from 2, processed by 3)\n",
      "job2 (spawned from 4, processed by 6)\n",
      "job3 (spawned from 2, processed by 4)\n",
      "job3 (spawned from 3, processed by 6)\n",
      "job3 (spawned from 5, processed by 4)\n",
      "job2 (spawned from 3, processed by 6)\n",
      "job2 (spawned from 5, processed by 5)\n",
      "job1 (spawned from 5, processed by 2)\n",
      "job3 (spawned from 1, processed by 5)\n",
      "job1 (spawned from 6, processed by 2)\n",
      "job1 (spawned from 1, processed by 5)\n",
      "job2 (spawned from 6, processed by 6)\n",
      "job2 (spawned from 1, processed by 6)\n",
      "job3 (spawned from 6, processed by 1)\n"
     ]
    }
   ],
   "source": [
    "function threaded_fun()\n",
    "    x = threadid()\n",
    "    @spawn println(\"job1\", \" (spawned from $x, processed by $(threadid()))\")\n",
    "    @spawn println(\"job2\", \" (spawned from $x, processed by $(threadid()))\")\n",
    "    @spawn println(\"job3\", \" (spawned from $x, processed by $(threadid()))\")\n",
    "end\n",
    "\n",
    "for i in 1:nthreads()\n",
    "    @spawn threaded_fun()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job1 (spawned from 6, processed by 6)\n",
      "job2 (spawned from 6, processed by 6)\n",
      "job3 (spawned from 6, processed by 6)\n",
      "job1 (spawned from 2, processed by 2)\n",
      "job2 (spawned from 2, processed by 2)\n",
      "job3 (spawned from 2, processed by 2)\n",
      "job1 (spawned from 5, processed by 5)\n",
      "job2 (spawned from 5, processed by 5)\n",
      "job3 (spawned from 5, processed by 5)\n",
      "job1 (spawned from 1, processed by 1)\n",
      "job2 (spawned from 1, processed by 1)\n",
      "job3 (spawned from 1, processed by 1)\n",
      "job1 (spawned from 4, processed by 4)\n",
      "job2 (spawned from 4, processed by 4)\n",
      "job3 (spawned from 4, processed by 4)\n",
      "job1 (spawned from 3, processed by 3)\n",
      "job2 (spawned from 3, processed by 3)\n",
      "job3 (spawned from 3, processed by 3)\n"
     ]
    }
   ],
   "source": [
    "function threaded_fun2()\n",
    "    x = threadid()\n",
    "    @threads for i in 1:3\n",
    "        println(\"job$i\", \" (spawned from $x, processed by $(threadid()))\")\n",
    "    end\n",
    "end\n",
    "\n",
    "@threads for i in 1:nthreads()\n",
    "    threaded_fun2()\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
