{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel computing is a programming method that **harnesses the power of multiple processors (or cores) at once**. Once of concern only to programmers of large supercomputers, modern computers now almost always have multi-core processors. However:\n",
    "\n",
    "> At the heart of efficient parallel code is fast serial code!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many CPU cores do I have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Hwloc\n",
    "Hwloc.num_physical_cores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Note that `Sys.CPU_THREADS` may or may not be equal to the number above. It indicates the number of CPUs + Hyperthreads.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why go parallel?\n",
    "\n",
    "<img src=\"imgs/42-years-processor-trend.svg\" width=700px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Amdahl's Law**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive expectation: I have 4 cores, give me my 4x speedup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">If $p$ is the fraction of a code that can be parallelized than the maximal theoretical speedup by parallelizing on $n$ cores is given by $F(n) = 1/(1-p + p/n)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip840\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip840)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip841\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip840)\" d=\"\n",
       "M196.857 1423.18 L2352.76 1423.18 L2352.76 47.2441 L196.857 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip842\">\n",
       "    <rect x=\"196\" y=\"47\" width=\"2157\" height=\"1377\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  529.055,1423.18 529.055,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  935.829,1423.18 935.829,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1342.6,1423.18 1342.6,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1749.38,1423.18 1749.38,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2156.15,1423.18 2156.15,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  196.857,1423.18 2352.76,1423.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  196.857,47.2441 2352.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  529.055,1423.18 529.055,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  935.829,1423.18 935.829,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1342.6,1423.18 1342.6,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1749.38,1423.18 1749.38,1406.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2156.15,1423.18 2156.15,1406.67 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M 0 0 M533.303 1465.22 Q536.659 1465.94 538.534 1468.2 Q540.433 1470.47 540.433 1473.81 Q540.433 1478.92 536.914 1481.72 Q533.396 1484.52 526.914 1484.52 Q524.738 1484.52 522.423 1484.08 Q520.132 1483.67 517.678 1482.81 L517.678 1478.3 Q519.623 1479.43 521.937 1480.01 Q524.252 1480.59 526.775 1480.59 Q531.173 1480.59 533.465 1478.85 Q535.78 1477.12 535.78 1473.81 Q535.78 1470.75 533.627 1469.04 Q531.497 1467.3 527.678 1467.3 L523.65 1467.3 L523.65 1463.46 L527.863 1463.46 Q531.312 1463.46 533.141 1462.09 Q534.97 1460.7 534.97 1458.11 Q534.97 1455.45 533.072 1454.04 Q531.197 1452.6 527.678 1452.6 Q525.757 1452.6 523.558 1453.02 Q521.359 1453.44 518.72 1454.31 L518.72 1450.15 Q521.382 1449.41 523.697 1449.04 Q526.035 1448.67 528.095 1448.67 Q533.419 1448.67 536.521 1451.1 Q539.622 1453.5 539.622 1457.63 Q539.622 1460.5 537.979 1462.49 Q536.335 1464.45 533.303 1465.22 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M936.234 1464.71 Q933.086 1464.71 931.234 1466.86 Q929.405 1469.01 929.405 1472.76 Q929.405 1476.49 931.234 1478.67 Q933.086 1480.82 936.234 1480.82 Q939.382 1480.82 941.211 1478.67 Q943.062 1476.49 943.062 1472.76 Q943.062 1469.01 941.211 1466.86 Q939.382 1464.71 936.234 1464.71 M945.516 1450.06 L945.516 1454.31 Q943.757 1453.48 941.951 1453.04 Q940.169 1452.6 938.41 1452.6 Q933.78 1452.6 931.326 1455.73 Q928.896 1458.85 928.549 1465.17 Q929.914 1463.16 931.975 1462.09 Q934.035 1461 936.512 1461 Q941.72 1461 944.729 1464.18 Q947.762 1467.32 947.762 1472.76 Q947.762 1478.09 944.613 1481.31 Q941.465 1484.52 936.234 1484.52 Q930.238 1484.52 927.067 1479.94 Q923.896 1475.33 923.896 1466.61 Q923.896 1458.41 927.785 1453.55 Q931.674 1448.67 938.225 1448.67 Q939.984 1448.67 941.766 1449.01 Q943.572 1449.36 945.516 1450.06 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1332.9 1483.13 L1332.9 1478.88 Q1334.66 1479.71 1336.47 1480.15 Q1338.27 1480.59 1340.01 1480.59 Q1344.64 1480.59 1347.07 1477.49 Q1349.52 1474.36 1349.87 1468.02 Q1348.53 1470.01 1346.47 1471.07 Q1344.41 1472.14 1341.91 1472.14 Q1336.72 1472.14 1333.69 1469.01 Q1330.68 1465.87 1330.68 1460.43 Q1330.68 1455.1 1333.83 1451.88 Q1336.98 1448.67 1342.21 1448.67 Q1348.2 1448.67 1351.35 1453.27 Q1354.52 1457.86 1354.52 1466.61 Q1354.52 1474.78 1350.63 1479.66 Q1346.77 1484.52 1340.22 1484.52 Q1338.46 1484.52 1336.65 1484.18 Q1334.85 1483.83 1332.9 1483.13 M1342.21 1468.48 Q1345.36 1468.48 1347.19 1466.33 Q1349.04 1464.18 1349.04 1460.43 Q1349.04 1456.7 1347.19 1454.55 Q1345.36 1452.37 1342.21 1452.37 Q1339.06 1452.37 1337.21 1454.55 Q1335.38 1456.7 1335.38 1460.43 Q1335.38 1464.18 1337.21 1466.33 Q1339.06 1468.48 1342.21 1468.48 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1727.05 1479.92 L1734.69 1479.92 L1734.69 1453.55 L1726.38 1455.22 L1726.38 1450.96 L1734.64 1449.29 L1739.32 1449.29 L1739.32 1479.92 L1746.96 1479.92 L1746.96 1483.85 L1727.05 1483.85 L1727.05 1479.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1756.05 1479.92 L1772.37 1479.92 L1772.37 1483.85 L1750.43 1483.85 L1750.43 1479.92 Q1753.09 1477.16 1757.67 1472.53 Q1762.28 1467.88 1763.46 1466.54 Q1765.71 1464.01 1766.59 1462.28 Q1767.49 1460.52 1767.49 1458.83 Q1767.49 1456.07 1765.54 1454.34 Q1763.62 1452.6 1760.52 1452.6 Q1758.32 1452.6 1755.87 1453.37 Q1753.44 1454.13 1750.66 1455.68 L1750.66 1450.96 Q1753.48 1449.82 1755.94 1449.25 Q1758.39 1448.67 1760.43 1448.67 Q1765.8 1448.67 1768.99 1451.35 Q1772.19 1454.04 1772.19 1458.53 Q1772.19 1460.66 1771.38 1462.58 Q1770.59 1464.48 1768.48 1467.07 Q1767.91 1467.74 1764.8 1470.96 Q1761.7 1474.15 1756.05 1479.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M2133.52 1479.92 L2141.16 1479.92 L2141.16 1453.55 L2132.85 1455.22 L2132.85 1450.96 L2141.11 1449.29 L2145.79 1449.29 L2145.79 1479.92 L2153.43 1479.92 L2153.43 1483.85 L2133.52 1483.85 L2133.52 1479.92 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M2158.54 1449.29 L2176.9 1449.29 L2176.9 1453.23 L2162.83 1453.23 L2162.83 1461.7 Q2163.85 1461.35 2164.86 1461.19 Q2165.88 1461 2166.9 1461 Q2172.69 1461 2176.07 1464.18 Q2179.45 1467.35 2179.45 1472.76 Q2179.45 1478.34 2175.98 1481.44 Q2172.5 1484.52 2166.18 1484.52 Q2164.01 1484.52 2161.74 1484.15 Q2159.49 1483.78 2157.09 1483.04 L2157.09 1478.34 Q2159.17 1479.48 2161.39 1480.03 Q2163.61 1480.59 2166.09 1480.59 Q2170.1 1480.59 2172.43 1478.48 Q2174.77 1476.38 2174.77 1472.76 Q2174.77 1469.15 2172.43 1467.05 Q2170.1 1464.94 2166.09 1464.94 Q2164.22 1464.94 2162.34 1465.36 Q2160.49 1465.77 2158.54 1466.65 L2158.54 1449.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1061.01 1546.53 L1061.01 1568.04 L1055.16 1568.04 L1055.16 1546.72 Q1055.16 1541.66 1053.18 1539.14 Q1051.21 1536.63 1047.26 1536.63 Q1042.52 1536.63 1039.78 1539.65 Q1037.05 1542.68 1037.05 1547.9 L1037.05 1568.04 L1031.16 1568.04 L1031.16 1532.4 L1037.05 1532.4 L1037.05 1537.93 Q1039.15 1534.72 1041.98 1533.13 Q1044.85 1531.54 1048.57 1531.54 Q1054.71 1531.54 1057.86 1535.36 Q1061.01 1539.14 1061.01 1546.53 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1066.55 1553.98 L1066.55 1532.4 L1072.41 1532.4 L1072.41 1553.75 Q1072.41 1558.81 1074.38 1561.36 Q1076.36 1563.87 1080.3 1563.87 Q1085.04 1563.87 1087.78 1560.85 Q1090.55 1557.83 1090.55 1552.61 L1090.55 1532.4 L1096.41 1532.4 L1096.41 1568.04 L1090.55 1568.04 L1090.55 1562.57 Q1088.42 1565.82 1085.59 1567.41 Q1082.78 1568.97 1079.06 1568.97 Q1072.92 1568.97 1069.74 1565.15 Q1066.55 1561.33 1066.55 1553.98 M1081.29 1531.54 L1081.29 1531.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1130.3 1539.24 Q1132.5 1535.29 1135.56 1533.41 Q1138.61 1531.54 1142.75 1531.54 Q1148.32 1531.54 1151.34 1535.45 Q1154.37 1539.33 1154.37 1546.53 L1154.37 1568.04 L1148.48 1568.04 L1148.48 1546.72 Q1148.48 1541.59 1146.66 1539.11 Q1144.85 1536.63 1141.13 1536.63 Q1136.58 1536.63 1133.93 1539.65 Q1131.29 1542.68 1131.29 1547.9 L1131.29 1568.04 L1125.4 1568.04 L1125.4 1546.72 Q1125.4 1541.56 1123.59 1539.11 Q1121.77 1536.63 1117.99 1536.63 Q1113.5 1536.63 1110.86 1539.68 Q1108.22 1542.71 1108.22 1547.9 L1108.22 1568.04 L1102.33 1568.04 L1102.33 1532.4 L1108.22 1532.4 L1108.22 1537.93 Q1110.22 1534.66 1113.02 1533.1 Q1115.82 1531.54 1119.67 1531.54 Q1123.56 1531.54 1126.26 1533.51 Q1129 1535.48 1130.3 1539.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1186.1 1550.25 Q1186.1 1543.79 1183.43 1540.13 Q1180.79 1536.44 1176.14 1536.44 Q1171.49 1536.44 1168.82 1540.13 Q1166.18 1543.79 1166.18 1550.25 Q1166.18 1556.71 1168.82 1560.4 Q1171.49 1564.07 1176.14 1564.07 Q1180.79 1564.07 1183.43 1560.4 Q1186.1 1556.71 1186.1 1550.25 M1166.18 1537.81 Q1168.02 1534.62 1170.82 1533.1 Q1173.66 1531.54 1177.57 1531.54 Q1184.06 1531.54 1188.11 1536.69 Q1192.18 1541.85 1192.18 1550.25 Q1192.18 1558.65 1188.11 1563.81 Q1184.06 1568.97 1177.57 1568.97 Q1173.66 1568.97 1170.82 1567.44 Q1168.02 1565.88 1166.18 1562.7 L1166.18 1568.04 L1160.29 1568.04 L1160.29 1518.52 L1166.18 1518.52 L1166.18 1537.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1228.81 1548.76 L1228.81 1551.62 L1201.89 1551.62 Q1202.27 1557.67 1205.52 1560.85 Q1208.79 1564 1214.62 1564 Q1217.99 1564 1221.14 1563.17 Q1224.33 1562.35 1227.45 1560.69 L1227.45 1566.23 Q1224.29 1567.57 1220.98 1568.27 Q1217.67 1568.97 1214.27 1568.97 Q1205.74 1568.97 1200.74 1564 Q1195.78 1559.04 1195.78 1550.57 Q1195.78 1541.82 1200.49 1536.69 Q1205.23 1531.54 1213.25 1531.54 Q1220.44 1531.54 1224.61 1536.18 Q1228.81 1540.8 1228.81 1548.76 M1222.96 1547.04 Q1222.89 1542.23 1220.25 1539.37 Q1217.64 1536.5 1213.31 1536.5 Q1208.41 1536.5 1205.45 1539.27 Q1202.52 1542.04 1202.08 1547.07 L1222.96 1547.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1255.61 1537.87 Q1254.63 1537.3 1253.45 1537.04 Q1252.3 1536.76 1250.9 1536.76 Q1245.94 1536.76 1243.26 1540 Q1240.62 1543.22 1240.62 1549.27 L1240.62 1568.04 L1234.73 1568.04 L1234.73 1532.4 L1240.62 1532.4 L1240.62 1537.93 Q1242.47 1534.69 1245.43 1533.13 Q1248.39 1531.54 1252.62 1531.54 Q1253.23 1531.54 1253.96 1531.63 Q1254.69 1531.7 1255.58 1531.85 L1255.61 1537.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1296.29 1536.5 Q1291.58 1536.5 1288.84 1540.19 Q1286.11 1543.85 1286.11 1550.25 Q1286.11 1556.65 1288.81 1560.34 Q1291.55 1564 1296.29 1564 Q1300.97 1564 1303.71 1560.31 Q1306.44 1556.62 1306.44 1550.25 Q1306.44 1543.92 1303.71 1540.23 Q1300.97 1536.5 1296.29 1536.5 M1296.29 1531.54 Q1303.93 1531.54 1308.29 1536.5 Q1312.65 1541.47 1312.65 1550.25 Q1312.65 1559 1308.29 1564 Q1303.93 1568.97 1296.29 1568.97 Q1288.62 1568.97 1284.26 1564 Q1279.93 1559 1279.93 1550.25 Q1279.93 1541.47 1284.26 1536.5 Q1288.62 1531.54 1296.29 1531.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1336.84 1518.52 L1336.84 1523.39 L1331.24 1523.39 Q1328.09 1523.39 1326.85 1524.66 Q1325.64 1525.93 1325.64 1529.24 L1325.64 1532.4 L1335.28 1532.4 L1335.28 1536.95 L1325.64 1536.95 L1325.64 1568.04 L1319.75 1568.04 L1319.75 1536.95 L1314.15 1536.95 L1314.15 1532.4 L1319.75 1532.4 L1319.75 1529.91 Q1319.75 1523.96 1322.52 1521.26 Q1325.29 1518.52 1331.3 1518.52 L1336.84 1518.52 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1389.36 1533.76 L1389.36 1539.24 Q1386.87 1537.87 1384.36 1537.2 Q1381.88 1536.5 1379.33 1536.5 Q1373.63 1536.5 1370.48 1540.13 Q1367.33 1543.73 1367.33 1550.25 Q1367.33 1556.78 1370.48 1560.4 Q1373.63 1564 1379.33 1564 Q1381.88 1564 1384.36 1563.33 Q1386.87 1562.63 1389.36 1561.26 L1389.36 1566.68 Q1386.91 1567.82 1384.26 1568.39 Q1381.65 1568.97 1378.69 1568.97 Q1370.64 1568.97 1365.9 1563.91 Q1361.16 1558.85 1361.16 1550.25 Q1361.16 1541.53 1365.93 1536.53 Q1370.74 1531.54 1379.08 1531.54 Q1381.78 1531.54 1384.36 1532.11 Q1386.94 1532.65 1389.36 1533.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1409.31 1536.5 Q1404.6 1536.5 1401.87 1540.19 Q1399.13 1543.85 1399.13 1550.25 Q1399.13 1556.65 1401.83 1560.34 Q1404.57 1564 1409.31 1564 Q1413.99 1564 1416.73 1560.31 Q1419.47 1556.62 1419.47 1550.25 Q1419.47 1543.92 1416.73 1540.23 Q1413.99 1536.5 1409.31 1536.5 M1409.31 1531.54 Q1416.95 1531.54 1421.31 1536.5 Q1425.67 1541.47 1425.67 1550.25 Q1425.67 1559 1421.31 1564 Q1416.95 1568.97 1409.31 1568.97 Q1401.64 1568.97 1397.28 1564 Q1392.95 1559 1392.95 1550.25 Q1392.95 1541.47 1397.28 1536.5 Q1401.64 1531.54 1409.31 1531.54 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1452.47 1537.87 Q1451.49 1537.3 1450.31 1537.04 Q1449.16 1536.76 1447.76 1536.76 Q1442.8 1536.76 1440.12 1540 Q1437.48 1543.22 1437.48 1549.27 L1437.48 1568.04 L1431.59 1568.04 L1431.59 1532.4 L1437.48 1532.4 L1437.48 1537.93 Q1439.33 1534.69 1442.29 1533.13 Q1445.25 1531.54 1449.48 1531.54 Q1450.09 1531.54 1450.82 1531.63 Q1451.55 1531.7 1452.44 1531.85 L1452.47 1537.87 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1487.68 1548.76 L1487.68 1551.62 L1460.75 1551.62 Q1461.13 1557.67 1464.38 1560.85 Q1467.66 1564 1473.48 1564 Q1476.85 1564 1480.01 1563.17 Q1483.19 1562.35 1486.31 1560.69 L1486.31 1566.23 Q1483.16 1567.57 1479.85 1568.27 Q1476.54 1568.97 1473.13 1568.97 Q1464.6 1568.97 1459.6 1564 Q1454.64 1559.04 1454.64 1550.57 Q1454.64 1541.82 1459.35 1536.69 Q1464.09 1531.54 1472.11 1531.54 Q1479.3 1531.54 1483.47 1536.18 Q1487.68 1540.8 1487.68 1548.76 M1481.82 1547.04 Q1481.76 1542.23 1479.11 1539.37 Q1476.5 1536.5 1472.18 1536.5 Q1467.27 1536.5 1464.31 1539.27 Q1461.39 1542.04 1460.94 1547.07 L1481.82 1547.04 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M1516.54 1533.45 L1516.54 1538.98 Q1514.06 1537.71 1511.39 1537.07 Q1508.71 1536.44 1505.85 1536.44 Q1501.49 1536.44 1499.29 1537.77 Q1497.13 1539.11 1497.13 1541.79 Q1497.13 1543.82 1498.69 1545 Q1500.25 1546.15 1504.96 1547.2 L1506.96 1547.64 Q1513.2 1548.98 1515.81 1551.43 Q1518.45 1553.85 1518.45 1558.21 Q1518.45 1563.17 1514.51 1566.07 Q1510.59 1568.97 1503.72 1568.97 Q1500.85 1568.97 1497.73 1568.39 Q1494.65 1567.85 1491.21 1566.74 L1491.21 1560.69 Q1494.46 1562.38 1497.61 1563.24 Q1500.76 1564.07 1503.84 1564.07 Q1507.98 1564.07 1510.21 1562.66 Q1512.44 1561.23 1512.44 1558.65 Q1512.44 1556.27 1510.82 1554.99 Q1509.22 1553.72 1503.78 1552.54 L1501.74 1552.07 Q1496.3 1550.92 1493.88 1548.56 Q1491.46 1546.18 1491.46 1542.04 Q1491.46 1537.01 1495.03 1534.27 Q1498.59 1531.54 1505.15 1531.54 Q1508.4 1531.54 1511.26 1532.01 Q1514.13 1532.49 1516.54 1533.45 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  196.857,1211.16 2352.76,1211.16 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  196.857,951.554 2352.76,951.554 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  196.857,691.944 2352.76,691.944 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  196.857,432.333 2352.76,432.333 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  196.857,172.723 2352.76,172.723 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  196.857,1423.18 196.857,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2352.76,1423.18 2352.76,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  196.857,1211.16 222.728,1211.16 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  196.857,951.554 222.728,951.554 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  196.857,691.944 222.728,691.944 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  196.857,432.333 222.728,432.333 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  196.857,172.723 222.728,172.723 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M 0 0 M153.728 1209.81 Q157.084 1210.53 158.959 1212.8 Q160.857 1215.07 160.857 1218.4 Q160.857 1223.51 157.339 1226.31 Q153.82 1229.12 147.339 1229.12 Q145.163 1229.12 142.848 1228.68 Q140.556 1228.26 138.103 1227.4 L138.103 1222.89 Q140.047 1224.02 142.362 1224.6 Q144.677 1225.18 147.2 1225.18 Q151.598 1225.18 153.89 1223.44 Q156.204 1221.71 156.204 1218.4 Q156.204 1215.34 154.052 1213.63 Q151.922 1211.89 148.103 1211.89 L144.075 1211.89 L144.075 1208.05 L148.288 1208.05 Q151.737 1208.05 153.566 1206.69 Q155.394 1205.3 155.394 1202.7 Q155.394 1200.04 153.496 1198.63 Q151.621 1197.19 148.103 1197.19 Q146.181 1197.19 143.982 1197.61 Q141.783 1198.03 139.144 1198.91 L139.144 1194.74 Q141.806 1194 144.121 1193.63 Q146.459 1193.26 148.519 1193.26 Q153.843 1193.26 156.945 1195.69 Q160.047 1198.1 160.047 1202.22 Q160.047 1205.09 158.403 1207.08 Q156.76 1209.05 153.728 1209.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M149.329 949.691 Q146.181 949.691 144.329 951.843 Q142.501 953.996 142.501 957.746 Q142.501 961.473 144.329 963.649 Q146.181 965.802 149.329 965.802 Q152.478 965.802 154.306 963.649 Q156.158 961.473 156.158 957.746 Q156.158 953.996 154.306 951.843 Q152.478 949.691 149.329 949.691 M158.612 935.038 L158.612 939.297 Q156.853 938.464 155.047 938.024 Q153.265 937.584 151.505 937.584 Q146.876 937.584 144.422 940.709 Q141.991 943.834 141.644 950.154 Q143.01 948.14 145.07 947.075 Q147.13 945.987 149.607 945.987 Q154.815 945.987 157.825 949.158 Q160.857 952.306 160.857 957.746 Q160.857 963.07 157.709 966.288 Q154.561 969.505 149.329 969.505 Q143.334 969.505 140.163 964.922 Q136.992 960.316 136.992 951.589 Q136.992 943.394 140.88 938.533 Q144.769 933.649 151.32 933.649 Q153.079 933.649 154.862 933.996 Q156.667 934.344 158.612 935.038 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M139.237 708.506 L139.237 704.247 Q140.996 705.08 142.802 705.52 Q144.607 705.96 146.343 705.96 Q150.973 705.96 153.403 702.858 Q155.857 699.733 156.204 693.39 Q154.862 695.381 152.802 696.446 Q150.741 697.511 148.241 697.511 Q143.056 697.511 140.024 694.386 Q137.015 691.238 137.015 685.798 Q137.015 680.474 140.163 677.256 Q143.311 674.039 148.542 674.039 Q154.538 674.039 157.686 678.645 Q160.857 683.228 160.857 691.978 Q160.857 700.15 156.968 705.034 Q153.103 709.895 146.552 709.895 Q144.792 709.895 142.987 709.548 Q141.181 709.2 139.237 708.506 M148.542 693.853 Q151.691 693.853 153.519 691.7 Q155.371 689.548 155.371 685.798 Q155.371 682.071 153.519 679.918 Q151.691 677.742 148.542 677.742 Q145.394 677.742 143.542 679.918 Q141.714 682.071 141.714 685.798 Q141.714 689.548 143.542 691.7 Q145.394 693.853 148.542 693.853 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M115.533 445.678 L123.172 445.678 L123.172 419.312 L114.862 420.979 L114.862 416.72 L123.126 415.053 L127.802 415.053 L127.802 445.678 L135.441 445.678 L135.441 449.613 L115.533 449.613 L115.533 445.678 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M144.538 445.678 L160.857 445.678 L160.857 449.613 L138.913 449.613 L138.913 445.678 Q141.575 442.923 146.158 438.294 Q150.765 433.641 151.945 432.298 Q154.19 429.775 155.07 428.039 Q155.973 426.28 155.973 424.59 Q155.973 421.835 154.028 420.099 Q152.107 418.363 149.005 418.363 Q146.806 418.363 144.353 419.127 Q141.922 419.891 139.144 421.442 L139.144 416.72 Q141.968 415.585 144.422 415.007 Q146.876 414.428 148.913 414.428 Q154.283 414.428 157.478 417.113 Q160.672 419.798 160.672 424.289 Q160.672 426.419 159.862 428.34 Q159.075 430.238 156.968 432.831 Q156.39 433.502 153.288 436.72 Q150.186 439.914 144.538 445.678 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M114.931 186.067 L122.57 186.067 L122.57 159.702 L114.26 161.368 L114.26 157.109 L122.524 155.443 L127.2 155.443 L127.2 186.067 L134.839 186.067 L134.839 190.003 L114.931 190.003 L114.931 186.067 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M139.954 155.443 L158.311 155.443 L158.311 159.378 L144.237 159.378 L144.237 167.85 Q145.255 167.503 146.274 167.341 Q147.292 167.155 148.311 167.155 Q154.098 167.155 157.478 170.327 Q160.857 173.498 160.857 178.915 Q160.857 184.493 157.385 187.595 Q153.913 190.674 147.593 190.674 Q145.417 190.674 143.149 190.303 Q140.904 189.933 138.496 189.192 L138.496 184.493 Q140.579 185.628 142.802 186.183 Q145.024 186.739 147.501 186.739 Q151.505 186.739 153.843 184.632 Q156.181 182.526 156.181 178.915 Q156.181 175.304 153.843 173.197 Q151.505 171.091 147.501 171.091 Q145.626 171.091 143.751 171.507 Q141.899 171.924 139.954 172.804 L139.954 155.443 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M58.657 964.632 L77.5631 964.632 L77.5631 970.52 L28.3562 970.52 L28.3562 964.632 L33.7671 964.632 Q30.5842 962.786 29.0564 959.985 Q27.4968 957.152 27.4968 953.237 Q27.4968 946.744 32.6531 942.702 Q37.8093 938.628 46.212 938.628 Q54.6147 938.628 59.771 942.702 Q64.9272 946.744 64.9272 953.237 Q64.9272 957.152 63.3994 959.985 Q61.8398 962.786 58.657 964.632 M46.212 944.707 Q39.7508 944.707 36.0905 947.381 Q32.3984 950.023 32.3984 954.67 Q32.3984 959.317 36.0905 961.99 Q39.7508 964.632 46.212 964.632 Q52.6732 964.632 56.3653 961.99 Q60.0256 959.317 60.0256 954.67 Q60.0256 950.023 56.3653 947.381 Q52.6732 944.707 46.212 944.707 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M46.0847 916.284 Q46.0847 923.382 47.7079 926.12 Q49.3312 928.857 53.2461 928.857 Q56.3653 928.857 58.2114 926.82 Q60.0256 924.751 60.0256 921.218 Q60.0256 916.348 56.5881 913.42 Q53.1188 910.46 47.3897 910.46 L46.0847 910.46 L46.0847 916.284 M43.6657 904.603 L64.0042 904.603 L64.0042 910.46 L58.5933 910.46 Q61.8398 912.465 63.3994 915.457 Q64.9272 918.449 64.9272 922.778 Q64.9272 928.252 61.8716 931.499 Q58.7843 934.713 53.6281 934.713 Q47.6125 934.713 44.5569 930.703 Q41.5014 926.661 41.5014 918.672 L41.5014 910.46 L40.9285 910.46 Q36.8862 910.46 34.6901 913.133 Q32.4621 915.775 32.4621 920.581 Q32.4621 923.637 33.1941 926.533 Q33.9262 929.43 35.3903 932.103 L29.9795 932.103 Q28.7381 928.889 28.1334 925.865 Q27.4968 922.841 27.4968 919.977 Q27.4968 912.242 31.5072 908.423 Q35.5176 904.603 43.6657 904.603 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M33.8307 877.804 Q33.2578 878.79 33.0032 879.968 Q32.7167 881.114 32.7167 882.514 Q32.7167 887.48 35.9632 890.153 Q39.1779 892.795 45.2253 892.795 L64.0042 892.795 L64.0042 898.683 L28.3562 898.683 L28.3562 892.795 L33.8944 892.795 Q30.6479 890.949 29.0883 887.989 Q27.4968 885.029 27.4968 880.796 Q27.4968 880.191 27.5923 879.459 Q27.656 878.727 27.8151 877.836 L33.8307 877.804 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M46.0847 855.46 Q46.0847 862.558 47.7079 865.295 Q49.3312 868.032 53.2461 868.032 Q56.3653 868.032 58.2114 865.995 Q60.0256 863.927 60.0256 860.394 Q60.0256 855.524 56.5881 852.596 Q53.1188 849.636 47.3897 849.636 L46.0847 849.636 L46.0847 855.46 M43.6657 843.779 L64.0042 843.779 L64.0042 849.636 L58.5933 849.636 Q61.8398 851.641 63.3994 854.633 Q64.9272 857.625 64.9272 861.953 Q64.9272 867.428 61.8716 870.674 Q58.7843 873.889 53.6281 873.889 Q47.6125 873.889 44.5569 869.878 Q41.5014 865.836 41.5014 857.847 L41.5014 849.636 L40.9285 849.636 Q36.8862 849.636 34.6901 852.309 Q32.4621 854.951 32.4621 859.757 Q32.4621 862.813 33.1941 865.709 Q33.9262 868.605 35.3903 871.279 L29.9795 871.279 Q28.7381 868.064 28.1334 865.041 Q27.4968 862.017 27.4968 859.152 Q27.4968 851.418 31.5072 847.599 Q35.5176 843.779 43.6657 843.779 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M14.479 837.636 L14.479 831.78 L64.0042 831.78 L64.0042 837.636 L14.479 837.636 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M14.479 825.637 L14.479 819.78 L64.0042 819.78 L64.0042 825.637 L14.479 825.637 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M44.7161 783.146 L47.5806 783.146 L47.5806 810.073 Q53.6281 809.691 56.8109 806.444 Q59.9619 803.166 59.9619 797.341 Q59.9619 793.967 59.1344 790.816 Q58.3069 787.634 56.6518 784.514 L62.1899 784.514 Q63.5267 787.665 64.227 790.976 Q64.9272 794.286 64.9272 797.691 Q64.9272 806.221 59.9619 811.219 Q54.9967 816.184 46.5303 816.184 Q37.7774 816.184 32.6531 811.473 Q27.4968 806.731 27.4968 798.71 Q27.4968 791.517 32.1438 787.347 Q36.7589 783.146 44.7161 783.146 M42.9973 789.002 Q38.1912 789.066 35.3266 791.708 Q32.4621 794.318 32.4621 798.646 Q32.4621 803.548 35.2312 806.508 Q38.0002 809.436 43.0292 809.882 L42.9973 789.002 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M14.479 777.003 L14.479 771.146 L64.0042 771.146 L64.0042 777.003 L14.479 777.003 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M29.4065 721.558 L34.9447 721.558 Q33.6716 724.04 33.035 726.714 Q32.3984 729.387 32.3984 732.252 Q32.3984 736.612 33.7352 738.809 Q35.072 740.973 37.7456 740.973 Q39.7826 740.973 40.9603 739.413 Q42.1061 737.854 43.1565 733.143 L43.6021 731.138 Q44.9389 724.9 47.3897 722.29 Q49.8086 719.648 54.1691 719.648 Q59.1344 719.648 62.0308 723.595 Q64.9272 727.509 64.9272 734.384 Q64.9272 737.249 64.3543 740.368 Q63.8132 743.456 62.6992 746.893 L56.6518 746.893 Q58.3387 743.647 59.198 740.496 Q60.0256 737.344 60.0256 734.257 Q60.0256 730.119 58.6251 727.891 Q57.1929 725.663 54.6147 725.663 Q52.2276 725.663 50.9545 727.287 Q49.6813 728.878 48.5037 734.321 L48.0262 736.358 Q46.8804 741.8 44.5251 744.219 Q42.138 746.638 38.0002 746.638 Q32.9713 746.638 30.2341 743.074 Q27.4968 739.509 27.4968 732.952 Q27.4968 729.706 27.9743 726.841 Q28.4517 723.976 29.4065 721.558 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M58.657 707.839 L77.5631 707.839 L77.5631 713.728 L28.3562 713.728 L28.3562 707.839 L33.7671 707.839 Q30.5842 705.993 29.0564 703.192 Q27.4968 700.36 27.4968 696.445 Q27.4968 689.952 32.6531 685.91 Q37.8093 681.836 46.212 681.836 Q54.6147 681.836 59.771 685.91 Q64.9272 689.952 64.9272 696.445 Q64.9272 700.36 63.3994 703.192 Q61.8398 705.993 58.657 707.839 M46.212 687.915 Q39.7508 687.915 36.0905 690.588 Q32.3984 693.23 32.3984 697.877 Q32.3984 702.524 36.0905 705.198 Q39.7508 707.839 46.212 707.839 Q52.6732 707.839 56.3653 705.198 Q60.0256 702.524 60.0256 697.877 Q60.0256 693.23 56.3653 690.588 Q52.6732 687.915 46.212 687.915 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M44.7161 645.201 L47.5806 645.201 L47.5806 672.128 Q53.6281 671.746 56.8109 668.499 Q59.9619 665.221 59.9619 659.396 Q59.9619 656.023 59.1344 652.872 Q58.3069 649.689 56.6518 646.57 L62.1899 646.57 Q63.5267 649.721 64.227 653.031 Q64.9272 656.341 64.9272 659.747 Q64.9272 668.277 59.9619 673.274 Q54.9967 678.239 46.5303 678.239 Q37.7774 678.239 32.6531 673.528 Q27.4968 668.786 27.4968 660.765 Q27.4968 653.572 32.1438 649.402 Q36.7589 645.201 44.7161 645.201 M42.9973 651.057 Q38.1912 651.121 35.3266 653.763 Q32.4621 656.373 32.4621 660.701 Q32.4621 665.603 35.2312 668.563 Q38.0002 671.491 43.0292 671.937 L42.9973 651.057 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M44.7161 608.566 L47.5806 608.566 L47.5806 635.493 Q53.6281 635.111 56.8109 631.865 Q59.9619 628.586 59.9619 622.762 Q59.9619 619.388 59.1344 616.237 Q58.3069 613.054 56.6518 609.935 L62.1899 609.935 Q63.5267 613.086 64.227 616.396 Q64.9272 619.706 64.9272 623.112 Q64.9272 631.642 59.9619 636.639 Q54.9967 641.604 46.5303 641.604 Q37.7774 641.604 32.6531 636.894 Q27.4968 632.151 27.4968 624.13 Q27.4968 616.937 32.1438 612.768 Q36.7589 608.566 44.7161 608.566 M42.9973 614.423 Q38.1912 614.486 35.3266 617.128 Q32.4621 619.738 32.4621 624.067 Q32.4621 628.968 35.2312 631.928 Q38.0002 634.857 43.0292 635.302 L42.9973 614.423 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M33.7671 578.966 L14.479 578.966 L14.479 573.109 L64.0042 573.109 L64.0042 578.966 L58.657 578.966 Q61.8398 580.812 63.3994 583.644 Q64.9272 586.445 64.9272 590.392 Q64.9272 596.853 59.771 600.927 Q54.6147 604.97 46.212 604.97 Q37.8093 604.97 32.6531 600.927 Q27.4968 596.853 27.4968 590.392 Q27.4968 586.445 29.0564 583.644 Q30.5842 580.812 33.7671 578.966 M46.212 598.922 Q52.6732 598.922 56.3653 596.28 Q60.0256 593.607 60.0256 588.96 Q60.0256 584.313 56.3653 581.639 Q52.6732 578.966 46.212 578.966 Q39.7508 578.966 36.0905 581.639 Q32.3984 584.313 32.3984 588.96 Q32.3984 593.607 36.0905 596.28 Q39.7508 598.922 46.212 598.922 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M49.9359 567.571 L28.3562 567.571 L28.3562 561.715 L49.7131 561.715 Q54.7739 561.715 57.3202 559.741 Q59.8346 557.768 59.8346 553.821 Q59.8346 549.079 56.8109 546.341 Q53.7872 543.572 48.5673 543.572 L28.3562 543.572 L28.3562 537.716 L64.0042 537.716 L64.0042 543.572 L58.5296 543.572 Q61.7762 545.705 63.3676 548.538 Q64.9272 551.339 64.9272 555.062 Q64.9272 561.205 61.1078 564.388 Q57.2883 567.571 49.9359 567.571 M27.4968 552.834 L27.4968 552.834 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M58.657 525.908 L77.5631 525.908 L77.5631 531.796 L28.3562 531.796 L28.3562 525.908 L33.7671 525.908 Q30.5842 524.061 29.0564 521.261 Q27.4968 518.428 27.4968 514.513 Q27.4968 508.02 32.6531 503.978 Q37.8093 499.904 46.212 499.904 Q54.6147 499.904 59.771 503.978 Q64.9272 508.02 64.9272 514.513 Q64.9272 518.428 63.3994 521.261 Q61.8398 524.061 58.657 525.908 M46.212 505.983 Q39.7508 505.983 36.0905 508.656 Q32.3984 511.298 32.3984 515.945 Q32.3984 520.592 36.0905 523.266 Q39.7508 525.908 46.212 525.908 Q52.6732 525.908 56.3653 523.266 Q60.0256 520.592 60.0256 515.945 Q60.0256 511.298 56.3653 508.656 Q52.6732 505.983 46.212 505.983 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip842)\" style=\"stroke:#009af9; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  257.873,1384.24 393.464,1297.7 529.055,1211.16 664.646,1124.63 800.238,1038.09 935.829,951.554 1071.42,865.017 1207.01,778.48 1342.6,691.944 1478.19,605.407 \n",
       "  1613.78,518.87 1749.38,432.333 1884.97,345.796 2020.56,259.259 2156.15,172.723 2291.74,86.1857 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#e26f46; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  257.873,1384.24 393.464,1305.94 529.055,1234.77 664.646,1169.78 800.238,1110.2 935.829,1055.4 1071.42,1004.81 1207.01,957.964 1342.6,914.467 1478.19,873.969 \n",
       "  1613.78,836.172 1749.38,800.812 1884.97,767.663 2020.56,736.523 2156.15,707.215 2291.74,679.581 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#3da44d; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  257.873,1384.24 393.464,1313.44 529.055,1254.43 664.646,1204.51 800.238,1161.71 935.829,1124.63 1071.42,1092.18 1207.01,1063.54 1342.6,1038.09 1478.19,1015.32 \n",
       "  1613.78,994.822 1749.38,976.279 1884.97,959.421 2020.56,944.029 2156.15,929.92 2291.74,916.939 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#c271d2; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  257.873,1384.24 393.464,1326.55 529.055,1285.34 664.646,1254.43 800.238,1230.39 935.829,1211.16 1071.42,1195.43 1207.01,1182.32 1342.6,1171.22 1478.19,1161.71 \n",
       "  1613.78,1153.47 1749.38,1146.26 1884.97,1139.9 2020.56,1134.24 2156.15,1129.18 2291.74,1124.63 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#ac8d18; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  257.873,1384.24 393.464,1347.15 529.055,1326.55 664.646,1313.44 800.238,1304.36 935.829,1297.7 1071.42,1292.61 1207.01,1288.59 1342.6,1285.34 1478.19,1282.65 \n",
       "  1613.78,1280.39 1749.38,1278.47 1884.97,1276.81 2020.56,1275.37 2156.15,1274.1 2291.74,1272.98 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#00a9ad; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  257.873,1384.24 393.464,1362.6 529.055,1352.77 664.646,1347.15 800.238,1343.52 935.829,1340.97 1071.42,1339.09 1207.01,1337.64 1342.6,1336.49 1478.19,1335.56 \n",
       "  1613.78,1334.79 1749.38,1334.14 1884.97,1333.58 2020.56,1333.1 2156.15,1332.68 2291.74,1332.32 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip842)\" style=\"stroke:#ed5d92; stroke-width:8; stroke-opacity:1; fill:none\" points=\"\n",
       "  257.873,1384.24 393.464,1374.62 529.055,1370.92 664.646,1368.97 800.238,1367.76 935.829,1366.93 1071.42,1366.33 1207.01,1365.88 1342.6,1365.53 1478.19,1365.24 \n",
       "  1613.78,1365.01 1749.38,1364.81 1884.97,1364.65 2020.56,1364.5 2156.15,1364.38 2291.74,1364.27 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"\n",
       "M268.72 576.949 L625.301 576.949 L625.301 93.1086 L268.72 93.1086  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  268.72,576.949 625.301,576.949 625.301,93.1086 268.72,93.1086 268.72,576.949 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip840)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  292.675,153.589 436.401,153.589 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M 0 0 M461.027 166.933 L468.666 166.933 L468.666 140.568 L460.356 142.235 L460.356 137.975 L468.62 136.309 L473.296 136.309 L473.296 166.933 L480.934 166.933 L480.934 170.869 L461.027 170.869 L461.027 166.933 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M496.004 139.387 Q492.393 139.387 490.564 142.952 Q488.758 146.494 488.758 153.623 Q488.758 160.73 490.564 164.295 Q492.393 167.836 496.004 167.836 Q499.638 167.836 501.444 164.295 Q503.272 160.73 503.272 153.623 Q503.272 146.494 501.444 142.952 Q499.638 139.387 496.004 139.387 M496.004 135.684 Q501.814 135.684 504.87 140.29 Q507.948 144.873 507.948 153.623 Q507.948 162.35 504.87 166.957 Q501.814 171.54 496.004 171.54 Q490.194 171.54 487.115 166.957 Q484.059 162.35 484.059 153.623 Q484.059 144.873 487.115 140.29 Q490.194 135.684 496.004 135.684 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M523.018 139.387 Q519.406 139.387 517.578 142.952 Q515.772 146.494 515.772 153.623 Q515.772 160.73 517.578 164.295 Q519.406 167.836 523.018 167.836 Q526.652 167.836 528.457 164.295 Q530.286 160.73 530.286 153.623 Q530.286 146.494 528.457 142.952 Q526.652 139.387 523.018 139.387 M523.018 135.684 Q528.828 135.684 531.883 140.29 Q534.962 144.873 534.962 153.623 Q534.962 162.35 531.883 166.957 Q528.828 171.54 523.018 171.54 Q517.207 171.54 514.129 166.957 Q511.073 162.35 511.073 153.623 Q511.073 144.873 514.129 140.29 Q517.207 135.684 523.018 135.684 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M569.429 155.66 Q567.415 155.66 566.258 157.373 Q565.124 159.086 565.124 162.142 Q565.124 165.151 566.258 166.887 Q567.415 168.6 569.429 168.6 Q571.397 168.6 572.531 166.887 Q573.689 165.151 573.689 162.142 Q573.689 159.109 572.531 157.396 Q571.397 155.66 569.429 155.66 M569.429 152.721 Q573.087 152.721 575.24 155.267 Q577.392 157.813 577.392 162.142 Q577.392 166.47 575.216 169.017 Q573.064 171.54 569.429 171.54 Q565.726 171.54 563.573 169.017 Q561.42 166.47 561.42 162.142 Q561.42 157.79 563.573 155.267 Q565.749 152.721 569.429 152.721 M545.541 138.623 Q543.55 138.623 542.392 140.36 Q541.258 142.072 541.258 145.082 Q541.258 148.137 542.392 149.85 Q543.527 151.563 545.541 151.563 Q547.554 151.563 548.689 149.85 Q549.846 148.137 549.846 145.082 Q549.846 142.096 548.689 140.36 Q547.531 138.623 545.541 138.623 M566.443 135.684 L570.147 135.684 L548.527 171.54 L544.823 171.54 L566.443 135.684 M545.541 135.684 Q549.198 135.684 551.374 138.23 Q553.55 140.753 553.55 145.082 Q553.55 149.457 551.374 151.98 Q549.221 154.503 545.541 154.503 Q541.86 154.503 539.707 151.98 Q537.578 149.434 537.578 145.082 Q537.578 140.776 539.73 138.23 Q541.883 135.684 545.541 135.684 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip840)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  292.675,214.069 436.401,214.069 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M 0 0 M462.578 230.631 L462.578 226.372 Q464.337 227.205 466.143 227.645 Q467.948 228.085 469.685 228.085 Q474.314 228.085 476.745 224.983 Q479.198 221.858 479.546 215.515 Q478.203 217.506 476.143 218.571 Q474.083 219.636 471.583 219.636 Q466.398 219.636 463.365 216.511 Q460.356 213.363 460.356 207.923 Q460.356 202.599 463.504 199.381 Q466.652 196.164 471.884 196.164 Q477.879 196.164 481.027 200.77 Q484.198 205.353 484.198 214.103 Q484.198 222.275 480.309 227.159 Q476.444 232.02 469.893 232.02 Q468.134 232.02 466.328 231.673 Q464.523 231.325 462.578 230.631 M471.884 215.978 Q475.032 215.978 476.86 213.826 Q478.712 211.673 478.712 207.923 Q478.712 204.196 476.86 202.043 Q475.032 199.867 471.884 199.867 Q468.735 199.867 466.884 202.043 Q465.055 204.196 465.055 207.923 Q465.055 211.673 466.884 213.826 Q468.735 215.978 471.884 215.978 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M489.314 196.789 L507.67 196.789 L507.67 200.724 L493.596 200.724 L493.596 209.196 Q494.615 208.849 495.633 208.687 Q496.652 208.502 497.67 208.502 Q503.457 208.502 506.837 211.673 Q510.217 214.844 510.217 220.261 Q510.217 225.839 506.745 228.941 Q503.272 232.02 496.953 232.02 Q494.777 232.02 492.508 231.65 Q490.263 231.279 487.856 230.538 L487.856 225.839 Q489.939 226.974 492.161 227.529 Q494.383 228.085 496.86 228.085 Q500.865 228.085 503.203 225.978 Q505.541 223.872 505.541 220.261 Q505.541 216.65 503.203 214.543 Q500.865 212.437 496.86 212.437 Q494.985 212.437 493.11 212.853 Q491.258 213.27 489.314 214.15 L489.314 196.789 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M544.684 216.14 Q542.67 216.14 541.513 217.853 Q540.379 219.566 540.379 222.622 Q540.379 225.631 541.513 227.367 Q542.67 229.08 544.684 229.08 Q546.652 229.08 547.786 227.367 Q548.943 225.631 548.943 222.622 Q548.943 219.589 547.786 217.876 Q546.652 216.14 544.684 216.14 M544.684 213.201 Q548.342 213.201 550.494 215.747 Q552.647 218.293 552.647 222.622 Q552.647 226.95 550.471 229.497 Q548.318 232.02 544.684 232.02 Q540.98 232.02 538.828 229.497 Q536.675 226.95 536.675 222.622 Q536.675 218.27 538.828 215.747 Q541.004 213.201 544.684 213.201 M520.795 199.103 Q518.805 199.103 517.647 200.84 Q516.513 202.552 516.513 205.562 Q516.513 208.617 517.647 210.33 Q518.781 212.043 520.795 212.043 Q522.809 212.043 523.943 210.33 Q525.101 208.617 525.101 205.562 Q525.101 202.576 523.943 200.84 Q522.786 199.103 520.795 199.103 M541.698 196.164 L545.402 196.164 L523.781 232.02 L520.078 232.02 L541.698 196.164 M520.795 196.164 Q524.453 196.164 526.629 198.71 Q528.805 201.233 528.805 205.562 Q528.805 209.937 526.629 212.46 Q524.476 214.983 520.795 214.983 Q517.115 214.983 514.962 212.46 Q512.832 209.914 512.832 205.562 Q512.832 201.256 514.985 198.71 Q517.138 196.164 520.795 196.164 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip840)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  292.675,274.549 436.401,274.549 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M 0 0 M462.578 291.111 L462.578 286.852 Q464.337 287.685 466.143 288.125 Q467.948 288.565 469.685 288.565 Q474.314 288.565 476.745 285.463 Q479.198 282.338 479.546 275.995 Q478.203 277.986 476.143 279.051 Q474.083 280.116 471.583 280.116 Q466.398 280.116 463.365 276.991 Q460.356 273.843 460.356 268.403 Q460.356 263.079 463.504 259.861 Q466.652 256.644 471.884 256.644 Q477.879 256.644 481.027 261.25 Q484.198 265.833 484.198 274.583 Q484.198 282.755 480.309 287.639 Q476.444 292.5 469.893 292.5 Q468.134 292.5 466.328 292.153 Q464.523 291.805 462.578 291.111 M471.884 276.458 Q475.032 276.458 476.86 274.306 Q478.712 272.153 478.712 268.403 Q478.712 264.676 476.86 262.523 Q475.032 260.347 471.884 260.347 Q468.735 260.347 466.884 262.523 Q465.055 264.676 465.055 268.403 Q465.055 272.153 466.884 274.306 Q468.735 276.458 471.884 276.458 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M499.268 260.347 Q495.657 260.347 493.828 263.912 Q492.022 267.454 492.022 274.583 Q492.022 281.69 493.828 285.255 Q495.657 288.796 499.268 288.796 Q502.902 288.796 504.707 285.255 Q506.536 281.69 506.536 274.583 Q506.536 267.454 504.707 263.912 Q502.902 260.347 499.268 260.347 M499.268 256.644 Q505.078 256.644 508.133 261.25 Q511.212 265.833 511.212 274.583 Q511.212 283.31 508.133 287.917 Q505.078 292.5 499.268 292.5 Q493.458 292.5 490.379 287.917 Q487.323 283.31 487.323 274.583 Q487.323 265.833 490.379 261.25 Q493.458 256.644 499.268 256.644 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M545.679 276.62 Q543.666 276.62 542.508 278.333 Q541.374 280.046 541.374 283.102 Q541.374 286.111 542.508 287.847 Q543.666 289.56 545.679 289.56 Q547.647 289.56 548.781 287.847 Q549.939 286.111 549.939 283.102 Q549.939 280.069 548.781 278.356 Q547.647 276.62 545.679 276.62 M545.679 273.681 Q549.337 273.681 551.49 276.227 Q553.642 278.773 553.642 283.102 Q553.642 287.43 551.466 289.977 Q549.314 292.5 545.679 292.5 Q541.976 292.5 539.823 289.977 Q537.67 287.43 537.67 283.102 Q537.67 278.75 539.823 276.227 Q541.999 273.681 545.679 273.681 M521.791 259.583 Q519.8 259.583 518.643 261.32 Q517.508 263.032 517.508 266.042 Q517.508 269.097 518.643 270.81 Q519.777 272.523 521.791 272.523 Q523.805 272.523 524.939 270.81 Q526.096 269.097 526.096 266.042 Q526.096 263.056 524.939 261.32 Q523.781 259.583 521.791 259.583 M542.693 256.644 L546.397 256.644 L524.777 292.5 L521.073 292.5 L542.693 256.644 M521.791 256.644 Q525.448 256.644 527.624 259.19 Q529.8 261.713 529.8 266.042 Q529.8 270.417 527.624 272.94 Q525.471 275.463 521.791 275.463 Q518.11 275.463 515.957 272.94 Q513.828 270.394 513.828 266.042 Q513.828 261.736 515.981 259.19 Q518.133 256.644 521.791 256.644 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip840)\" style=\"stroke:#c271d2; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  292.675,335.029 436.401,335.029 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M 0 0 M472.208 335.897 Q468.874 335.897 466.953 337.679 Q465.055 339.461 465.055 342.586 Q465.055 345.711 466.953 347.494 Q468.874 349.276 472.208 349.276 Q475.541 349.276 477.462 347.494 Q479.384 345.688 479.384 342.586 Q479.384 339.461 477.462 337.679 Q475.564 335.897 472.208 335.897 M467.532 333.906 Q464.523 333.165 462.833 331.105 Q461.166 329.045 461.166 326.082 Q461.166 321.938 464.106 319.531 Q467.069 317.124 472.208 317.124 Q477.37 317.124 480.309 319.531 Q483.249 321.938 483.249 326.082 Q483.249 329.045 481.559 331.105 Q479.893 333.165 476.907 333.906 Q480.286 334.693 482.161 336.985 Q484.059 339.276 484.059 342.586 Q484.059 347.61 480.981 350.295 Q477.925 352.98 472.208 352.98 Q466.49 352.98 463.411 350.295 Q460.356 347.61 460.356 342.586 Q460.356 339.276 462.254 336.985 Q464.152 334.693 467.532 333.906 M465.819 326.522 Q465.819 329.207 467.485 330.712 Q469.175 332.216 472.208 332.216 Q475.217 332.216 476.907 330.712 Q478.62 329.207 478.62 326.522 Q478.62 323.837 476.907 322.332 Q475.217 320.827 472.208 320.827 Q469.175 320.827 467.485 322.332 Q465.819 323.837 465.819 326.522 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M499.129 320.827 Q495.518 320.827 493.689 324.392 Q491.883 327.934 491.883 335.063 Q491.883 342.17 493.689 345.735 Q495.518 349.276 499.129 349.276 Q502.763 349.276 504.569 345.735 Q506.397 342.17 506.397 335.063 Q506.397 327.934 504.569 324.392 Q502.763 320.827 499.129 320.827 M499.129 317.124 Q504.939 317.124 507.995 321.73 Q511.073 326.313 511.073 335.063 Q511.073 343.79 507.995 348.397 Q504.939 352.98 499.129 352.98 Q493.319 352.98 490.24 348.397 Q487.184 343.79 487.184 335.063 Q487.184 326.313 490.24 321.73 Q493.319 317.124 499.129 317.124 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M545.541 337.1 Q543.527 337.1 542.369 338.813 Q541.235 340.526 541.235 343.582 Q541.235 346.591 542.369 348.327 Q543.527 350.04 545.541 350.04 Q547.508 350.04 548.642 348.327 Q549.8 346.591 549.8 343.582 Q549.8 340.549 548.642 338.836 Q547.508 337.1 545.541 337.1 M545.541 334.161 Q549.198 334.161 551.351 336.707 Q553.504 339.253 553.504 343.582 Q553.504 347.91 551.328 350.457 Q549.175 352.98 545.541 352.98 Q541.837 352.98 539.684 350.457 Q537.531 347.91 537.531 343.582 Q537.531 339.23 539.684 336.707 Q541.86 334.161 545.541 334.161 M521.652 320.063 Q519.661 320.063 518.504 321.8 Q517.369 323.512 517.369 326.522 Q517.369 329.577 518.504 331.29 Q519.638 333.003 521.652 333.003 Q523.666 333.003 524.8 331.29 Q525.957 329.577 525.957 326.522 Q525.957 323.536 524.8 321.8 Q523.643 320.063 521.652 320.063 M542.555 317.124 L546.258 317.124 L524.638 352.98 L520.934 352.98 L542.555 317.124 M521.652 317.124 Q525.309 317.124 527.485 319.67 Q529.661 322.193 529.661 326.522 Q529.661 330.897 527.485 333.42 Q525.332 335.943 521.652 335.943 Q517.971 335.943 515.819 333.42 Q513.689 330.874 513.689 326.522 Q513.689 322.216 515.842 319.67 Q517.994 317.124 521.652 317.124 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip840)\" style=\"stroke:#ac8d18; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  292.675,395.509 436.401,395.509 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M 0 0 M472.694 393.645 Q469.546 393.645 467.694 395.798 Q465.865 397.951 465.865 401.701 Q465.865 405.428 467.694 407.603 Q469.546 409.756 472.694 409.756 Q475.842 409.756 477.671 407.603 Q479.522 405.428 479.522 401.701 Q479.522 397.951 477.671 395.798 Q475.842 393.645 472.694 393.645 M481.976 378.993 L481.976 383.252 Q480.217 382.418 478.411 381.979 Q476.629 381.539 474.87 381.539 Q470.24 381.539 467.786 384.664 Q465.356 387.789 465.009 394.108 Q466.374 392.094 468.435 391.029 Q470.495 389.942 472.972 389.942 Q478.18 389.942 481.189 393.113 Q484.221 396.261 484.221 401.701 Q484.221 407.025 481.073 410.242 Q477.925 413.46 472.694 413.46 Q466.698 413.46 463.527 408.877 Q460.356 404.27 460.356 395.543 Q460.356 387.349 464.245 382.488 Q468.134 377.604 474.684 377.604 Q476.444 377.604 478.226 377.951 Q480.032 378.298 481.976 378.993 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M499.291 381.307 Q495.68 381.307 493.851 384.872 Q492.046 388.414 492.046 395.543 Q492.046 402.65 493.851 406.215 Q495.68 409.756 499.291 409.756 Q502.925 409.756 504.731 406.215 Q506.559 402.65 506.559 395.543 Q506.559 388.414 504.731 384.872 Q502.925 381.307 499.291 381.307 M499.291 377.604 Q505.101 377.604 508.157 382.21 Q511.235 386.793 511.235 395.543 Q511.235 404.27 508.157 408.877 Q505.101 413.46 499.291 413.46 Q493.481 413.46 490.402 408.877 Q487.346 404.27 487.346 395.543 Q487.346 386.793 490.402 382.21 Q493.481 377.604 499.291 377.604 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M545.703 397.58 Q543.689 397.58 542.531 399.293 Q541.397 401.006 541.397 404.062 Q541.397 407.071 542.531 408.807 Q543.689 410.52 545.703 410.52 Q547.67 410.52 548.804 408.807 Q549.962 407.071 549.962 404.062 Q549.962 401.029 548.804 399.316 Q547.67 397.58 545.703 397.58 M545.703 394.641 Q549.36 394.641 551.513 397.187 Q553.666 399.733 553.666 404.062 Q553.666 408.39 551.49 410.937 Q549.337 413.46 545.703 413.46 Q541.999 413.46 539.846 410.937 Q537.693 408.39 537.693 404.062 Q537.693 399.71 539.846 397.187 Q542.022 394.641 545.703 394.641 M521.814 380.543 Q519.823 380.543 518.666 382.28 Q517.531 383.992 517.531 387.002 Q517.531 390.057 518.666 391.77 Q519.8 393.483 521.814 393.483 Q523.828 393.483 524.962 391.77 Q526.119 390.057 526.119 387.002 Q526.119 384.016 524.962 382.28 Q523.805 380.543 521.814 380.543 M542.717 377.604 L546.42 377.604 L524.8 413.46 L521.096 413.46 L542.717 377.604 M521.814 377.604 Q525.471 377.604 527.647 380.15 Q529.823 382.673 529.823 387.002 Q529.823 391.377 527.647 393.9 Q525.494 396.423 521.814 396.423 Q518.133 396.423 515.981 393.9 Q513.851 391.354 513.851 387.002 Q513.851 382.696 516.004 380.15 Q518.156 377.604 521.814 377.604 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip840)\" style=\"stroke:#00a9ad; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  292.675,455.989 436.401,455.989 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M 0 0 M475.958 442.783 L464.152 461.232 L475.958 461.232 L475.958 442.783 M474.731 438.709 L480.61 438.709 L480.61 461.232 L485.541 461.232 L485.541 465.121 L480.61 465.121 L480.61 473.269 L475.958 473.269 L475.958 465.121 L460.356 465.121 L460.356 460.607 L474.731 438.709 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M500.61 441.787 Q496.999 441.787 495.17 445.352 Q493.365 448.894 493.365 456.023 Q493.365 463.13 495.17 466.695 Q496.999 470.236 500.61 470.236 Q504.245 470.236 506.05 466.695 Q507.879 463.13 507.879 456.023 Q507.879 448.894 506.05 445.352 Q504.245 441.787 500.61 441.787 M500.61 438.084 Q506.42 438.084 509.476 442.69 Q512.555 447.273 512.555 456.023 Q512.555 464.75 509.476 469.357 Q506.42 473.94 500.61 473.94 Q494.8 473.94 491.721 469.357 Q488.666 464.75 488.666 456.023 Q488.666 447.273 491.721 442.69 Q494.8 438.084 500.61 438.084 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M547.022 458.06 Q545.008 458.06 543.851 459.773 Q542.717 461.486 542.717 464.542 Q542.717 467.551 543.851 469.287 Q545.008 471 547.022 471 Q548.99 471 550.124 469.287 Q551.281 467.551 551.281 464.542 Q551.281 461.509 550.124 459.796 Q548.99 458.06 547.022 458.06 M547.022 455.121 Q550.679 455.121 552.832 457.667 Q554.985 460.213 554.985 464.542 Q554.985 468.87 552.809 471.417 Q550.656 473.94 547.022 473.94 Q543.318 473.94 541.166 471.417 Q539.013 468.87 539.013 464.542 Q539.013 460.19 541.166 457.667 Q543.342 455.121 547.022 455.121 M523.133 441.023 Q521.143 441.023 519.985 442.76 Q518.851 444.472 518.851 447.482 Q518.851 450.537 519.985 452.25 Q521.119 453.963 523.133 453.963 Q525.147 453.963 526.281 452.25 Q527.439 450.537 527.439 447.482 Q527.439 444.496 526.281 442.76 Q525.124 441.023 523.133 441.023 M544.036 438.084 L547.74 438.084 L526.119 473.94 L522.416 473.94 L544.036 438.084 M523.133 438.084 Q526.791 438.084 528.967 440.63 Q531.143 443.153 531.143 447.482 Q531.143 451.857 528.967 454.38 Q526.814 456.903 523.133 456.903 Q519.453 456.903 517.3 454.38 Q515.17 451.834 515.17 447.482 Q515.17 443.176 517.323 440.63 Q519.476 438.084 523.133 438.084 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip840)\" style=\"stroke:#ed5d92; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  292.675,516.469 436.401,516.469 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip840)\" d=\"M 0 0 M465.981 529.813 L482.3 529.813 L482.3 533.749 L460.356 533.749 L460.356 529.813 Q463.018 527.059 467.601 522.429 Q472.208 517.776 473.388 516.434 Q475.634 513.911 476.513 512.175 Q477.416 510.415 477.416 508.726 Q477.416 505.971 475.472 504.235 Q473.55 502.499 470.448 502.499 Q468.249 502.499 465.796 503.263 Q463.365 504.027 460.587 505.577 L460.587 500.855 Q463.411 499.721 465.865 499.142 Q468.319 498.564 470.356 498.564 Q475.726 498.564 478.921 501.249 Q482.115 503.934 482.115 508.425 Q482.115 510.554 481.305 512.476 Q480.518 514.374 478.411 516.966 Q477.833 517.638 474.731 520.855 Q471.629 524.05 465.981 529.813 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M497.37 502.267 Q493.758 502.267 491.93 505.832 Q490.124 509.374 490.124 516.503 Q490.124 523.61 491.93 527.175 Q493.758 530.716 497.37 530.716 Q501.004 530.716 502.809 527.175 Q504.638 523.61 504.638 516.503 Q504.638 509.374 502.809 505.832 Q501.004 502.267 497.37 502.267 M497.37 498.564 Q503.18 498.564 506.235 503.17 Q509.314 507.753 509.314 516.503 Q509.314 525.23 506.235 529.837 Q503.18 534.42 497.37 534.42 Q491.559 534.42 488.481 529.837 Q485.425 525.23 485.425 516.503 Q485.425 507.753 488.481 503.17 Q491.559 498.564 497.37 498.564 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip840)\" d=\"M 0 0 M543.781 518.54 Q541.767 518.54 540.61 520.253 Q539.476 521.966 539.476 525.022 Q539.476 528.031 540.61 529.767 Q541.767 531.48 543.781 531.48 Q545.749 531.48 546.883 529.767 Q548.041 528.031 548.041 525.022 Q548.041 521.989 546.883 520.276 Q545.749 518.54 543.781 518.54 M543.781 515.601 Q547.439 515.601 549.592 518.147 Q551.744 520.693 551.744 525.022 Q551.744 529.35 549.568 531.897 Q547.416 534.42 543.781 534.42 Q540.078 534.42 537.925 531.897 Q535.772 529.35 535.772 525.022 Q535.772 520.67 537.925 518.147 Q540.101 515.601 543.781 515.601 M519.893 501.503 Q517.902 501.503 516.744 503.24 Q515.61 504.952 515.61 507.962 Q515.61 511.017 516.744 512.73 Q517.879 514.443 519.893 514.443 Q521.906 514.443 523.041 512.73 Q524.198 511.017 524.198 507.962 Q524.198 504.976 523.041 503.24 Q521.883 501.503 519.893 501.503 M540.795 498.564 L544.499 498.564 L522.879 534.42 L519.175 534.42 L540.795 498.564 M519.893 498.564 Q523.55 498.564 525.726 501.11 Q527.902 503.633 527.902 507.962 Q527.902 512.337 525.726 514.86 Q523.573 517.383 519.893 517.383 Q516.212 517.383 514.059 514.86 Q511.93 512.314 511.93 507.962 Q511.93 503.656 514.082 501.11 Q516.235 498.564 519.893 498.564 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Plots\n",
    "F(p,n) = 1/(1-p + p/n)\n",
    "\n",
    "pl = plot()\n",
    "for p in reverse(sort(vcat(0.2:0.2:1, [0.9, 0.95])))\n",
    "    plot!(pl, n -> F(p,n), 1:16, lab=\"$(Int(p*100))%\", lw=2,\n",
    "        legend=:topleft, xlab=\"number of cores\", ylab=\"parallel speedup\", frame=:box)\n",
    "end\n",
    "pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Computing in Julia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia documentation link: [Parallel computing](https://docs.julialang.org/en/v1/manual/parallel-computing/index.html)\n",
    "\n",
    "There are many types of parallelism, some of which are (from micro to macro)\n",
    "\n",
    "* **Instruction level parallelism**\n",
    "* **Multi-threading** (process shared memory)\n",
    "* **Tasks aka Coroutines** aka Green threads (more like cooperative multitasking, process shared memory)\n",
    "* **Multi-Core processing** (maybe system shared memory)\n",
    "* **Distributed processing** (same as above but involving multiple machines)\n",
    "\n",
    "Julia provides (more or less) native support for all of these forms of parallel processing (same order as above)\n",
    "\n",
    "* `@simd` and [SIMD.jl](https://github.com/eschnett/SIMD.jl)\n",
    "* `Base.Threads.@threads` (experimental since 2015 but seems to be fine)\n",
    "* `@async`, `@sync`, `Channel`\n",
    "* `@spawnat`, `@fetch`, `RemoteChannel`, `SharedArray`, etc.\n",
    "* `@spawnat`, `@fetch`, `RemoteChannel`, `DArray`, `MPI.jl` etc.\n",
    "\n",
    "With scientific computing in mind, we will mainly focus on how to distribute a process through multiple cores or machines (our thp cluster for example), that is **Multi-Core processing** and **Distributed processing**. But before we can do so, we have to learn how to control Julia's control flow through tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks (Control flow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, Julia waits for every command to finish and run everything sequentially.\n",
    "\n",
    "Tasks are a control flow feature that allows computations to be **suspended** and resumed in a flexible manner. This feature is sometimes called by other names, such as coroutines, green or lightweight threads and cooperative multitasking.\n",
    "\n",
    "To me, the name **cooperative multitasking** is the most descriptive. Tasks are managed/scheduled by Julia and can sometimes be run in a quasi-parallel fashion.\n",
    "\n",
    "An important use case is **asynchronous I/O**, which is typically slow. Examples are\n",
    " * **multiple user input** (Why not already process some of the input?)\n",
    " * **data dumping to disk** (Maybe it's possible to continue a calculation?)\n",
    " * **receiving calculations from worker processes** (We'll need that below!)\n",
    "\n",
    "How do we execute commands asynchronously?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `@async` and `@sync`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Based on [this](https://stackoverflow.com/questions/37287020/how-and-when-to-use-async-and-sync-in-julia/37287021#37287021) stackoverflow answer.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "@async\n",
       "\\end{verbatim}\n",
       "Wrap an expression in a \\href{@ref}{\\texttt{Task}} and add it to the local machine's scheduler queue.\n",
       "\n",
       "Values can be interpolated into \\texttt{@async} via \\texttt{\\$}, which copies the value directly into the constructed underlying closure. This allows you to insert the \\emph{value} of a variable, isolating the aysnchronous code from changes to the variable's value in the current task.\n",
       "\n",
       "\\begin{quote}\n",
       "\\textbf{compat}\n",
       "\n",
       "Julia 1.4\n",
       "\n",
       "Interpolating values via \\texttt{\\$} is available as of Julia 1.4.\n",
       "\n",
       "\\end{quote}\n"
      ],
      "text/markdown": [
       "```\n",
       "@async\n",
       "```\n",
       "\n",
       "Wrap an expression in a [`Task`](@ref) and add it to the local machine's scheduler queue.\n",
       "\n",
       "Values can be interpolated into `@async` via `$`, which copies the value directly into the constructed underlying closure. This allows you to insert the *value* of a variable, isolating the aysnchronous code from changes to the variable's value in the current task.\n",
       "\n",
       "!!! compat \"Julia 1.4\"\n",
       "    Interpolating values via `$` is available as of Julia 1.4.\n",
       "\n"
      ],
      "text/plain": [
       "\u001b[36m  @async\u001b[39m\n",
       "\n",
       "  Wrap an expression in a \u001b[36mTask\u001b[39m and add it to the local machine's scheduler\n",
       "  queue.\n",
       "\n",
       "  Values can be interpolated into \u001b[36m@async\u001b[39m via \u001b[36m$\u001b[39m, which copies the value\n",
       "  directly into the constructed underlying closure. This allows you to insert\n",
       "  the \u001b[4mvalue\u001b[24m of a variable, isolating the aysnchronous code from changes to the\n",
       "  variable's value in the current task.\n",
       "\n",
       "\u001b[39m\u001b[1m  │ \u001b[22m\u001b[39m\u001b[1mJulia 1.4\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m\n",
       "\u001b[39m\u001b[1m  │\u001b[22m  Interpolating values via \u001b[36m$\u001b[39m is available as of Julia 1.4."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?@async"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this means is that for whatever falls within its scope, Julia will start a task to then proceed to whatever comes next in the script **without waiting for the task to complete**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.004840 seconds (63 allocations: 1.656 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time sleep(2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.006214 seconds (6.19 k allocations: 362.957 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x00000001195b0490"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time @async sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia allows the script to proceed (and the `@time` macro to fully execute) without waiting for the task (in this case, sleeping for two seconds) to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `@sync` macro to synchronize, that is wait for, all encapsulated tasks. (see `?@sync`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.036058 seconds (1.60 k allocations: 88.297 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00000001195b1690"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time @sync @async sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, here it doesn't make much sense to write `@sync @async` - we could simply drop it altogether.\n",
    "\n",
    "A better example is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.014940 seconds (3.66 k allocations: 175.633 KiB)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00000001195b1d50"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time @sync begin\n",
    "    @async sleep(2.0)\n",
    "    @async sleep(2.0)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello class!\n",
      "Today is reverse day!\n"
     ]
    }
   ],
   "source": [
    "@sync begin\n",
    "    @async (sleep(2); println(\"Today is reverse day!\"))\n",
    "    @async (sleep(1); println(\" class!\"))\n",
    "    @async print(\"Hello\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed processing: Multi-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed computing in Julia means having **multiple separate Julia instances running on different cores** on the same or different machines.\n",
    "\n",
    "Data movement and communication between processes is explicit.\n",
    "\n",
    "Let's focus on the *multi-core* case (your laptop/desktop) and save some cluster fun for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Master-worker model\n",
    "\n",
    "Julia uses a *master-worker* paradigm for its native distributed parallelism.\n",
    "\n",
    "One master process coordinates all the worker processes, which perform the actual computations.\n",
    "\n",
    "By default, Julia starts with one process on one core. If this single process is all we have, than it is both the master and the worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributed # Loading all tools that we need for distributed computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nprocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nworkers() # the master is considered a worker as long as there are no real workers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To increase the number of workers, i.e. Julia processes, from within a Julia session we can use `addprocs`.\n",
    "\n",
    "Alternatively, when starting Julia from the command line, one can use the `-p` option. Example,\n",
    "\n",
    "```\n",
    "julia -p 4\n",
    "```\n",
    "\n",
    "will start Julia with 5 processes, 1 master and 4 workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(4) # I have 4 cores, so let's add 4 worker processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every process has a Julia internal `pid` (process id). The master is always 1. You can get the workers pids from `workers()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the 4 worker's pids aren't necessarily 2, 3, 4 and 5. Let's remove the processes and add them once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00000001195b1210"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers()) # rmprocs(array of pids of worker processes to remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nworkers() # only the master is left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One master to rule them all - `@spawn`, `@spawnat`, `@fetch`, `@fetchfrom`, `@everywhere`..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To execute commands and start computations on workers we can use the following macros\n",
    "\n",
    "* `@spawn`: run a command or a code block on any worker and return a `Future` to it's result. It's basically a version of `@async` for remote processes.\n",
    "* `@spawnat`: same as `@spawn` but one can choose a specific worker by providing its pid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Let's say we would like to generate a random matrix on one of the workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(6, 1, 10, nothing)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@spawn rand(2,2) # basically @async for remote process, i.e. returns immediately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Future(7, 1, 11, nothing)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = @spawn rand(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.214098  0.645814\n",
       " 0.412204  0.729633"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(result) # blocks, like @sync"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the combination of spawning at fetching is so common, there is `@fetch` which combines them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.387106  0.274702\n",
       " 0.429211  0.272657"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetch rand(2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which worker did the work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\t7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.405433  0.443601\n",
       " 0.121499  0.618639"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetch begin\n",
    "    println(myid());\n",
    "    rand(2,2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `@spawnat` and `@fetchfrom` we can delegate the work to a specific worker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 6\n",
       " 7\n",
       " 8\n",
       " 9"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\t7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 0.231075  0.370931\n",
       " 0.400976  0.973702"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetchfrom 7 begin\n",
    "    println(myid());\n",
    "    rand(2,2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `@sync` as a blocker to wait for all workers to complete their tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 8:\tHello\n",
      "      From worker 7:\t class!\n",
      "      From worker 6:\tToday is reverse day!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "@sync begin\n",
    "    pids = workers()\n",
    "    @spawnat pids[1] (sleep(2); println(\"Today is reverse day!\"))\n",
    "    @spawnat pids[2] (sleep(1); println(\" class!\"))\n",
    "    @spawnat pids[3] println(\"Hello\")\n",
    "end;\n",
    "println(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we understood all that, let's delegate a *complicated* calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "On worker 8:\nUndefVarError: #complicated_calculation not defined\ndeserialize_datatype at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:1252\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:826\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:833\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773 [inlined]\ndeserialize_global_from_main at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/clusterserialize.jl:180\n#3 at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/clusterserialize.jl:72 [inlined]\nforeach at ./abstractarray.jl:2009\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/clusterserialize.jl:72\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:919\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:830\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:833\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773 [inlined]\ndeserialize_msg at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/messages.jl:99\n#invokelatest#1 at ./essentials.jl:710 [inlined]\ninvokelatest at ./essentials.jl:709 [inlined]\nmessage_handler_loop at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:185\nprocess_tcp_streams at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:142\n#99 at ./task.jl:356",
     "output_type": "error",
     "traceback": [
      "On worker 8:\nUndefVarError: #complicated_calculation not defined\ndeserialize_datatype at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:1252\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:826\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:833\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773 [inlined]\ndeserialize_global_from_main at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/clusterserialize.jl:180\n#3 at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/clusterserialize.jl:72 [inlined]\nforeach at ./abstractarray.jl:2009\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/clusterserialize.jl:72\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:919\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:830\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773\nhandle_deserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:833\ndeserialize at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Serialization/src/Serialization.jl:773 [inlined]\ndeserialize_msg at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/messages.jl:99\n#invokelatest#1 at ./essentials.jl:710 [inlined]\ninvokelatest at ./essentials.jl:709 [inlined]\nmessage_handler_loop at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:185\nprocess_tcp_streams at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/process_messages.jl:142\n#99 at ./task.jl:356",
      "",
      "Stacktrace:",
      " [1] #remotecall_fetch#143 at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/remotecall.jl:394 [inlined]",
      " [2] remotecall_fetch(::Function, ::Distributed.Worker) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/remotecall.jl:386",
      " [3] remotecall_fetch(::Function, ::Int64; kwargs::Base.Iterators.Pairs{Union{},Union{},Tuple{},NamedTuple{(),Tuple{}}}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/remotecall.jl:421",
      " [4] remotecall_fetch(::Function, ::Int64) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/remotecall.jl:421",
      " [5] top-level scope at In[42]:8",
      " [6] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "using Random\n",
    "\n",
    "function complicated_calculation()\n",
    "    sleep(1) # so complex that it takes a long time :)\n",
    "    randexp(5)\n",
    "end\n",
    "\n",
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Think of every worker as a separate Julia instance.**\n",
    "\n",
    "We only defined `complicated_calculation()` on the master process. The function doesn't exist on any of the workers yet.\n",
    "\n",
    "The macro `@everywhere` comes for the rescue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin # execute this block on all workers\n",
    "    using Random\n",
    "    \n",
    "    function complicated_calculation()\n",
    "        sleep(1)\n",
    "        randexp(5) # lives in Random\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " 1.0177783087717163\n",
       " 0.8034452502023521\n",
       " 0.9458931076997351\n",
       " 1.4912678299276059\n",
       " 1.511716404199707"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetch complicated_calculation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data movement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a crucial difference between the following two pieces of code. Can you guess what it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method1 (generic function with 1 method)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function method1()\n",
    "    A = rand(100,100)\n",
    "    B = rand(100,100)\n",
    "    C = @fetch A^2 * B^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "method2 (generic function with 1 method)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function method2()\n",
    "    C = @fetch rand(100,100)^2 * rand(100,100)^2\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's benchmark them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  735.879 μs (128 allocations: 238.92 KiB)\n",
      "  506.297 μs (103 allocations: 81.97 KiB)\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools\n",
    "@btime method1();\n",
    "@btime method2();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1 is slower, because `A` and `B` are created on the master process, transferred to a worker, and squared and multiplied on the worker process before the result is finally transferred back to the master.\n",
    "\n",
    "Method 2, on the other hand, creates, squares, and multiplies the random matrix all on the work process and only submits the result to the master.\n",
    "\n",
    "Hence, `method1` is **transferring 3x as much data** between the master and the worker!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data movement is crucial!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this toy example, it's rather easy to identify the faster method.\n",
    "\n",
    "In a real program, however, understanding data movement does require more thought and likely some measurement.\n",
    "\n",
    "For example, if the first process needs matrix `A` in a follow-up computation then the first method might be better in this case. Or, if computing `A` is expensive and only the current process has it, then moving it to another process might be unavoidable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Computer latency at a human scale\n",
    "\n",
    "To understand why thinking about data is important it's instructive to look at the time scales involved in data access.\n",
    "\n",
    "<img src=\"imgs/latency_human_scales.png\" width=900px>\n",
    "\n",
    "(taken from https://www.prowesscorp.com/computer-latency-at-a-human-scale/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avoid globals (once more)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myglobal = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "whohas (generic function with 1 method)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function whohas(s::String)\n",
    "    @everywhere begin\n",
    "        var = Symbol($s)\n",
    "        if isdefined(Main, var)\n",
    "            println(\"$var exists.\")\n",
    "        else\n",
    "            println(\"Doesn't exist.\")\n",
    "        end\n",
    "    end\n",
    "    nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myglobal exists.\n",
      "      From worker 6:\tDoesn't exist.\n",
      "      From worker 7:\tDoesn't exist.\n",
      "      From worker 8:\tDoesn't exist.\n",
      "      From worker 9:\tDoesn't exist.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@fetchfrom 6 myglobal+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 7:\tDoesn't exist.\n",
      "myglobal exists.\n",
      "      From worker 6:\tmyglobal exists.\n",
      "      From worker 8:\tDoesn't exist.\n",
      "      From worker 9:\tDoesn't exist.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"myglobal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globals get copied to workers and continue to exist as globals even after the call.\n",
    "\n",
    "This could lead to memory accumulation if many globals are used (just as it would in a single Julia session).\n",
    "\n",
    "It's better to avoid them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicit data movement: `Channel` and `RemoteChannel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Channels in Julia are constructs to explicitly exchange data between workers.\n",
    "\n",
    "They implement `put!`, `take!`, `fetch`, `isready` and `wait` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ?Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Channel{Int64}(sz_max:5,sz_curr:0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch = Channel{Int}(5) # a channel that can hold up to 5 integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(ch) # something in the channel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put!(ch, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take!(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "put!(ch, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch(ch) # basically take without a bang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "take!(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be careful, `take!` and `put!` are blocking if the channel is empty or full!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "false"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take!(ch) if we execute this, while isready(ch) == false, the current Julia session will hang."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channels for inter-process data movement: `RemoteChannel`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A `Channel` is local to a process. Worker 2 cannot directly refer to a `Channel` on worker 3 and vice-versa.\n",
    "\n",
    "\n",
    "* A `RemoteChannel`, however, can put and take values across workers. A `RemoteChannel` can be thought of as a handle to a `Channel`.\n",
    "\n",
    "\n",
    "* Any process with a reference to a `RemoteChannel` can put and take items from the channel. Data is automatically sent to (or retrieved from) the process a `RemoteChannel` is associated with.\n",
    "\n",
    "\n",
    "* The process id, pid, associated with a `RemoteChannel` identifies the process where the backing store, i.e., the backing Channel exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?RemoteChannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(x) = x^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function f(x)\n",
    "    x^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f() = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "()->x^2 + y^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteChannel{Channel{Int64}}(7, 1, 18559)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creates a channel on the second worker process\n",
    "# create a RemoteChannel handle to this channel on the master process\n",
    "const mychannel = RemoteChannel(()->Channel{Int}(10), workers()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 6:\tDoesn't exist.\n",
      "mychannel exists.\n",
      "      From worker 9:\tDoesn't exist.\n",
      "      From worker 8:\tDoesn't exist.\n",
      "      From worker 7:\tDoesn't exist.\n",
      "      From worker 12:\tDoesn't exist.\n",
      "      From worker 10:\tDoesn't exist.\n",
      "      From worker 13:\tDoesn't exist.\n",
      "      From worker 11:\tDoesn't exist.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"mychannel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One could create a global constant mychannel everywhere\n",
    "@everywhere const mychannel = $mychannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 6:\tmychannel exists.\n",
      "      From worker 8:\tmychannel exists.\n",
      "      From worker 10:\tmychannel exists.\n",
      "      From worker 11:\tmychannel exists.\n",
      "      From worker 12:\tmychannel exists.\n",
      "      From worker 13:\tmychannel exists.\n",
      "      From worker 7:\tmychannel exists.\n",
      "mychannel exists.\n",
      "      From worker 9:\tmychannel exists.\n"
     ]
    }
   ],
   "source": [
    "whohas(\"mychannel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we said many times before, one should generally try to avoid globals. The following is preferable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteChannel{Channel{Int64}}(1, 1, 18609)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function do_something()\n",
    "    rc = RemoteChannel(()->Channel{Int}(10), 1) # lives on the master\n",
    "    @sync for p in workers()\n",
    "        @spawnat p put!(rc, myid())\n",
    "    end\n",
    "    return rc\n",
    "end\n",
    "\n",
    "r = do_something()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isready(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "take!(r) = 9\n",
      "take!(r) = 7\n",
      "take!(r) = 6\n",
      "take!(r) = 8\n",
      "take!(r) = 12\n",
      "take!(r) = 11\n",
      "take!(r) = 10\n",
      "take!(r) = 13\n"
     ]
    }
   ],
   "source": [
    "while isready(r)\n",
    "    @show take!(r)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Int64,1}:\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ecosystem also contains a couple of tools, that make data transfer even simpler. See for example [ParallelDataTransfer.jl](https://github.com/ChrisRackauckas/ParallelDataTransfer.jl/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallelizing the easy way - `@distributed` and `pmap`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have seen the build block of commands for distributed computing in Julia. Having scientific computing in mind, one might not always want to think about how to distribute the work and explicitly spawn tasks.\n",
    "\n",
    "Also, fortunately, many useful parallel computations do not require (much) data movement. A common example is a direct Monte Carlo simulation, where multiple processes can handle independent simulation trials simultaneously. (We'll get to that later!)\n",
    "\n",
    "Julia provides convenience macros to\n",
    " * Parallelize loops (`@distributed`)\n",
    " * Apply a function to all elements in some collection (`pmap`)\n",
    " \n",
    "Let's explore these!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed loops (`@distributed`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers()); addprocs(4); nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce(+, [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.359 s (0 allocations: 0 bytes)\n"
     ]
    }
   ],
   "source": [
    "# serial version - count heads in a series of coin tosses\n",
    "function add_serial(n)\n",
    "    c = 0\n",
    "    for i = 1:n\n",
    "        c += rand(Bool)\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "@btime add_serial(200_000_000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is trivially parallelizable since the loop iterations are independent of each other. We can distribute coin tosses over a couple of workers.\n",
    "\n",
    "Afterwards we combine the results, that is we sum them up. The combination process is generally called a *reduction*, and in this case `sum` is the *reducer function*.\n",
    "\n",
    "To distribute the for loop over worker processes Julia provides the `@distributed` macro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?@distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  394.557 ms (416 allocations: 17.02 KiB)\n"
     ]
    }
   ],
   "source": [
    "# distributed version\n",
    "function add_distributed(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        Int(rand(Bool))\n",
    "    end\n",
    "    return c\n",
    "end\n",
    "\n",
    "@btime add_distributed(200_000_000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributed version is about **4x faster**, which is all we could hope for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see who is doing the work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 16:\t1\n",
      "      From worker 14:\t0\n",
      "      From worker 15:\t1\n",
      "      From worker 17:\t0\n",
      "      From worker 16:\t1\n",
      "      From worker 14:\t0\n",
      "      From worker 15:\t1\n",
      "      From worker 17:\t0\n"
     ]
    }
   ],
   "source": [
    "# verbose distributed version\n",
    "function add_distributed(n)\n",
    "    c = @distributed (+) for i in 1:n\n",
    "        x = Int(rand(Bool))\n",
    "        println(x);\n",
    "        x\n",
    "    end\n",
    "    c\n",
    "end\n",
    "\n",
    "add_distributed(8);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apparently, the work is evenly distributed between the workers. By using `@distributed` we let Julia decide how to split up the work and can't control it ourselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common mistake when using `@distributed` is the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "function f(n)\n",
    "    a = 0\n",
    "    @distributed (+) for i in 1:n\n",
    "        a += 1\n",
    "    end\n",
    "    a\n",
    "end\n",
    "\n",
    "a = f(10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you expect the value of `a` to be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can (sort of) see what's happening by making everything global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 16:\t1\n",
      "      From worker 14:\t1\n",
      "      From worker 16:\t1\n",
      "      From worker 15:\t1\n",
      "      From worker 14:\t1\n",
      "      From worker 14:\t1\n",
      "      From worker 15:\t1\n",
      "      From worker 15:\t1\n",
      "      From worker 17:\t1\n",
      "      From worker 17:\t1\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "@distributed (+) for i in 1:10\n",
    "    println(\"1\")\n",
    "    global a += 1\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = 0\n",
      "      From worker 15:\ta = 3\n",
      "      From worker 16:\ta = 2\n",
      "      From worker 17:\ta = 2\n",
      "      From worker 14:\ta = 3\n"
     ]
    }
   ],
   "source": [
    "@everywhere @show a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variable `a` gets copied to the worker processes as it is referenced in the distributed loop. \n",
    "\n",
    "Every worker will then increment its copy of `a`.\n",
    "\n",
    "However, we do not save the result of the reduction (sum) but instead return `a` from the master process, which hasn't been altered at all.\n",
    "\n",
    "Corrected version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f2(n)\n",
    "    a = @distributed (+) for i in 1:n\n",
    "        1\n",
    "    end\n",
    "    a\n",
    "end\n",
    "\n",
    "a = f2(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if I don't want to reduce?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the mistake above, the following example might not have the effect one expects. **Why?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (runnable) @0x000000011591db10"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = zeros(10)\n",
    "@distributed for i = 1:10\n",
    "    a[i] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      From worker 17:\ta = [1.0, 2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      From worker 14:\ta = [0.0, 0.0, 0.0, 4.0, 5.0, 6.0, 0.0, 0.0, 0.0, 0.0]\n",
      "      From worker 16:\ta = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 9.0, 10.0]\n",
      "      From worker 15:\ta = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 7.0, 8.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "@everywhere @show a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `@distributed` without a reduction function returns a `Task`. It is basically a distributed version of `@spawn` for all the iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `SharedArray`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually make all processes operate on the same array, one can use a `SharedArray`.\n",
    "\n",
    "Note that a `SharedArray` only works if the **processes live on the same host**.\n",
    "\n",
    "The constructor of a SharedArray is\n",
    "\n",
    "```julia\n",
    "SharedArray{T,N}(dims::NTuple; init=false, pids=Int[])\n",
    "```\n",
    "\n",
    "which creates an `N`-dimensional shared array of a (bits) type `T` and size `dims` across the processes specified by `pids`.\n",
    "\n",
    "(If an `init` function, of signature `initfn(S::SharedArray)`, is specified, it is called on all the participating workers. You can specify that each worker runs the init function on a distinct portion of the array, thereby parallelizing initialization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using SharedArrays # must be loaded everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 Array{Float64,2}:\n",
       " 0.621376  0.918242  0.0677402\n",
       " 0.616497  0.777217  0.49885"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = rand(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×3 SharedArray{Float64,2}:\n",
       " 0.621376  0.918242  0.0677402\n",
       " 0.616497  0.777217  0.49885"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = SharedArray(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we know how to create and fill our `SharedArray` we can create a parallel fill function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 SharedArray{Float64,2}:\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_shared_problematic(N)\n",
    "    S = SharedMatrix{Float64}(N,N)\n",
    "    @distributed for i in 1:length(S)\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "fill_shared_problematic(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Why is the method in its current form problematic? Try to find out yourself by going to larger `N` and, for example, inspecting the minimum of the returned `SharedArray`!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going to larger matrix sizes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_shared_problematic(N)\n",
    "    S = SharedMatrix{Int64}(N,N)\n",
    "    @distributed for i in 1:length(S)\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "S = fill_shared_problematic(100)\n",
    "minimum(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note how sometimes the array isn't completely filled but still contains zeros. This is because it isn't filled **yet**!\n",
    "\n",
    "Check again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimum(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `@sync` to synchronize our distributed for loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×100 SharedArray{Int64,2}:\n",
       "   1  101  201  301  401  501  601  …  9401  9501  9601  9701  9801   9901\n",
       "   2  102  202  302  402  502  602     9402  9502  9602  9702  9802   9902\n",
       "   3  103  203  303  403  503  603     9403  9503  9603  9703  9803   9903\n",
       "   4  104  204  304  404  504  604     9404  9504  9604  9704  9804   9904\n",
       "   5  105  205  305  405  505  605     9405  9505  9605  9705  9805   9905\n",
       "   6  106  206  306  406  506  606  …  9406  9506  9606  9706  9806   9906\n",
       "   7  107  207  307  407  507  607     9407  9507  9607  9707  9807   9907\n",
       "   8  108  208  308  408  508  608     9408  9508  9608  9708  9808   9908\n",
       "   9  109  209  309  409  509  609     9409  9509  9609  9709  9809   9909\n",
       "  10  110  210  310  410  510  610     9410  9510  9610  9710  9810   9910\n",
       "  11  111  211  311  411  511  611  …  9411  9511  9611  9711  9811   9911\n",
       "  12  112  212  312  412  512  612     9412  9512  9612  9712  9812   9912\n",
       "  13  113  213  313  413  513  613     9413  9513  9613  9713  9813   9913\n",
       "   ⋮                        ⋮       ⋱           ⋮                    \n",
       "  89  189  289  389  489  589  689     9489  9589  9689  9789  9889   9989\n",
       "  90  190  290  390  490  590  690     9490  9590  9690  9790  9890   9990\n",
       "  91  191  291  391  491  591  691  …  9491  9591  9691  9791  9891   9991\n",
       "  92  192  292  392  492  592  692     9492  9592  9692  9792  9892   9992\n",
       "  93  193  293  393  493  593  693     9493  9593  9693  9793  9893   9993\n",
       "  94  194  294  394  494  594  694     9494  9594  9694  9794  9894   9994\n",
       "  95  195  295  395  495  595  695     9495  9595  9695  9795  9895   9995\n",
       "  96  196  296  396  496  596  696  …  9496  9596  9696  9796  9896   9996\n",
       "  97  197  297  397  497  597  697     9497  9597  9697  9797  9897   9997\n",
       "  98  198  298  398  498  598  698     9498  9598  9698  9798  9898   9998\n",
       "  99  199  299  399  499  599  699     9499  9599  9699  9799  9899   9999\n",
       " 100  200  300  400  500  600  700     9500  9600  9700  9800  9900  10000"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function fill_shared_problematic(N)\n",
    "    S = SharedMatrix{Int64}(N,N)\n",
    "    @sync @distributed for i in 1:length(S) # added @sync here\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "S = fill_shared_problematic(100)\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's **benchmark** this for a larger matrix size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.686558 seconds (18 allocations: 762.940 MiB, 27.05% gc time)\n"
     ]
    }
   ],
   "source": [
    "# regular array\n",
    "function fill_regular(N)\n",
    "    A = Matrix{Int64}(undef,N,N)\n",
    "    for i in 1:length(A)\n",
    "        A[i] = i\n",
    "    end\n",
    "    A\n",
    "end\n",
    "\n",
    "@time fill_regular(10000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.612611 seconds (151.48 k allocations: 7.597 MiB)\n"
     ]
    }
   ],
   "source": [
    "# shared array\n",
    "function fill_shared(N)\n",
    "    S = SharedMatrix{Int64}(N,N)\n",
    "    @sync @distributed for i in 1:length(S)\n",
    "        S[i] = i\n",
    "    end\n",
    "    S\n",
    "end\n",
    "\n",
    "@time fill_shared(10000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is of course just filling an array.\n",
    "\n",
    "If there were actual calculations it might actually be beneficial to distribute the work across workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel map: `pmap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function problematic()\n",
    "    a = zeros(nworkers())\n",
    "    @distributed for i in 1:nworkers()\n",
    "        a[i] = rand()\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcat([1,2,3],[4,5,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f (generic function with 2 methods)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function f()\n",
    "    a = @distributed vcat for i in 1:nworkers()\n",
    "        [rand()]\n",
    "    end\n",
    "    return a\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Array{Float64,1}:\n",
       " 0.3142900523154466\n",
       " 0.3809527024512105\n",
       " 0.18037120275561436\n",
       " 0.7135165609407452\n",
       " 0.7317714552902341\n",
       " 0.33585235235127486"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Int64,1}:\n",
       " 1\n",
       " 4\n",
       " 9"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map(x->x^2, [1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we merely wish to apply a function to all all elements in a collection.\n",
    "\n",
    "For those cases, Julia provides the `pmap` (parallel map) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say, we want to compute the singular values of a bunch of larger matrices in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Distributed, BenchmarkTools; rmprocs(workers()); addprocs(Hwloc.num_physical_cores()); nworkers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Array{Float64,1},1}:\n",
       " [99.8115865404185, 8.104380017052518, 7.867571042610965, 7.842624189488903, 7.636600172795622, 7.604574316643391, 7.522011714410369, 7.466434023715098, 7.315315384457005, 7.284933642948932  …  0.32420286766872514, 0.2517266177944077, 0.24100407005586766, 0.20281090488120068, 0.17383180382450727, 0.13878901320442108, 0.10806601007059867, 0.0698435525448929, 0.046827705193499776, 0.03347063299889672]\n",
       " [100.19318551596838, 7.977909745354462, 7.862018805594322, 7.760932427689784, 7.734653881774835, 7.579748394021507, 7.5003198790618875, 7.466901802078726, 7.384898756310459, 7.367744520723839  …  0.31366310398400427, 0.2528296181347127, 0.23526117182561734, 0.2252614808118175, 0.21669182376134702, 0.18489826995190478, 0.11905754978357318, 0.05420322485321452, 0.03882134860123696, 0.001940928396258713]\n",
       " [100.17697523241021, 7.956130919003491, 7.9058891054096785, 7.766155105621239, 7.674559275475458, 7.596615423818525, 7.516995691871714, 7.37334791391276, 7.351168690016107, 7.243541274669858  …  0.33142604177258456, 0.2936883299717059, 0.24934379029943785, 0.2405725197115781, 0.20411587854095994, 0.14813208518693244, 0.118926080245257, 0.08316001371659605, 0.06995469209286351, 0.011440154081877405]\n",
       " [99.84483332258894, 8.11372770738988, 7.866905642035004, 7.813988846090657, 7.699141567126442, 7.65666942530855, 7.550397513803764, 7.46304338338277, 7.403272226244599, 7.26702026295962  …  0.26634993104333476, 0.2583079786222091, 0.20826654098930153, 0.19053193405834656, 0.1752460078004609, 0.1574994546000739, 0.12062693203903553, 0.045269071429371595, 0.04304606794863546, 0.008367681463122398]\n",
       " [100.30973009648422, 7.977203923422556, 7.8370280597099535, 7.736861557505949, 7.609275023061187, 7.512841539086908, 7.4536262672257845, 7.4248179780102435, 7.347097571954167, 7.227329949191607  …  0.3045022481334734, 0.2726185827161209, 0.23086094824945133, 0.20710362619465666, 0.18136716967511224, 0.15545539376312678, 0.13070433103693624, 0.08860439623616415, 0.06025999564152016, 0.026294798559430156]\n",
       " [100.3480694702696, 8.174868967629006, 7.9297982537046225, 7.847196125074787, 7.6029566399671, 7.569514906700605, 7.428843302469984, 7.335252026031421, 7.32559045541381, 7.271466869419972  …  0.32517794155033497, 0.29044638968826886, 0.26531252701168934, 0.257369582879632, 0.19101374757349596, 0.18059423157860965, 0.13282372551873212, 0.1029095230062585, 0.06218176700435908, 0.028488356842897137]\n",
       " [100.96769377852753, 8.118782013509229, 7.8555549444307955, 7.711698831849382, 7.685460871101467, 7.533668475513811, 7.482589274668713, 7.349777359746593, 7.2527936742457175, 7.197025006205024  …  0.32148853454564835, 0.26998183925963815, 0.25227805156739425, 0.18258486821717576, 0.17723188848273685, 0.14842577438790389, 0.1309383040165323, 0.052866438677612954, 0.03806368505684393, 0.024417148603929444]\n",
       " [100.42653193241642, 7.941873044306627, 7.898019694779328, 7.754170294329546, 7.690025191438821, 7.528754642339438, 7.416223287340793, 7.401620144881454, 7.303026108113731, 7.245272851823475  …  0.2948427574000585, 0.2779791947381181, 0.2331079315461554, 0.22445664594063924, 0.1881750207313789, 0.17125529929819908, 0.10259494993941963, 0.08118423398790008, 0.03972893010206279, 0.02003657256077471]\n",
       " [100.57083024512623, 8.121561743571446, 7.877332211004631, 7.651041601913758, 7.539739566743176, 7.515118325195946, 7.46940866053184, 7.408456462664312, 7.359054900430188, 7.338985657225098  …  0.3154738852545284, 0.2512521507865298, 0.2175609085647588, 0.21159729828907628, 0.1625193585199989, 0.14959908438108285, 0.09054905974370543, 0.07680177702252132, 0.03789741405466427, 0.011364412876017941]\n",
       " [100.26503133514937, 7.972473750210552, 7.814796654243008, 7.764913051071334, 7.7210698084967095, 7.647829451901819, 7.559527418667559, 7.501404951302853, 7.415903758200651, 7.281554360878259  …  0.29336914674905207, 0.28230585426460436, 0.22807263054980403, 0.20428699244951143, 0.1850204463879012, 0.13635871820688986, 0.107517098925254, 0.0514723312522489, 0.040091692367168544, 0.015213051102422681]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@everywhere using LinearAlgebra\n",
    "\n",
    "M = Matrix{Float64}[rand(200,200) for i = 1:10]\n",
    "\n",
    "pmap(svdvals, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function myfunc(m)\n",
    "    println(myid())\n",
    "    return svdvals(m)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      From worker 51:\t51\n",
      "      From worker 46:\t46\n",
      "      From worker 49:\t49\n",
      "      From worker 47:\t47\n",
      "      From worker 50:\t50\n",
      "      From worker 51:\t51\n",
      "      From worker 46:\t46\n",
      "      From worker 49:\t49\n",
      "      From worker 47:\t47\n",
      "      From worker 48:\t48\n"
     ]
    }
   ],
   "source": [
    "# Check that really all of the workers participated\n",
    "pmap(m->begin println(myid()); svdvals(m) end, M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.073800 seconds (13.46 k allocations: 4.914 MiB)\n",
      "  0.059176 seconds (83 allocations: 4.219 MiB)\n",
      "  0.014113 seconds (745 allocations: 45.281 KiB)\n"
     ]
    }
   ],
   "source": [
    "function svds_loop(M)\n",
    "    svds = Vector{Vector{Float64}}(undef, 10)\n",
    "    for (i, m) in enumerate(M)\n",
    "        svds[i] = svdvals(m)\n",
    "    end\n",
    "    svds\n",
    "end\n",
    "\n",
    "@time svds_loop(M);\n",
    "@time svdvals.(M);\n",
    "@time pmap(svdvals, M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to choose which?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Julia's pmap is designed for the case where\n",
    "* each function call does a **large amount of work** and/or\n",
    "* the **workload is non-uniform**.\n",
    "\n",
    "In contrast, `@distributed` can handle situations where\n",
    "* **each iteration is tiny**, i.e. perhaps only summing two numbers and/or\n",
    "* each iteration **takes about the same time**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling things up: distributed computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have worked on multiple cores on a single machine, your laptop for example.\n",
    "\n",
    "Processes can live on other machines as well! This allows us to distribute our computation across computer clusters.\n",
    "\n",
    "In principle, the plan of action is the same as in the multi-core case. However, we have to take into account the different memory situation. In particular, **data movement is expensive** and we won't be able to use `SharedArray`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00000001c5360fd0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers()) # fresh start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating workers on the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding processes on different machines is not much harder than adding them on your local machine. In the following we will take the last example, calculating singular values of a bunch of matrices, and distribute it over multiple computers in our thp network.\n",
    "\n",
    "In Julia, starting worker processes is handled by [ClusterManagers](https://docs.julialang.org/en/stable/manual/parallel-computing/#ClusterManagers-1).\n",
    "\n",
    "* The default one is `LocalManager`. It is automatically used when running `addprocs(i::Integer)` and we have implicitly used it already!\n",
    "* The one we are going to use for the THP cluster is `SSHManager`. It is automatically used when running `addprocs(hostnames::Array)`.\n",
    "\n",
    "Other cluster managers for SLURM, PBS, and others are provided in [ClusterManagers.jl](https://github.com/JuliaParallel/ClusterManagers.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, starting processes on other computers can be done by `addprocs([\"l93\", \"l94\"])`, where `\"l93\"` and `\"l94\"` are hostnames. The only requirement is a **passwordless ssh access** to all specified hosts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Demonstrate in terminal from thp node*\n",
    "\n",
    "```julia\n",
    "using Distributed\n",
    "\n",
    "addprocs([\"l93\", \"l94\"])\n",
    "\n",
    "@everywhere println(gethostname())\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can also start multiple processes on different machines:\n",
    "```julia\n",
    "addprocs([(\"l93\", 2), (\"l94\", 3)]) # starts 2 workers on l92 and 3 workers on l93\n",
    "\n",
    "# Use :auto to start as many processes as CPUs are available\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `addprocs` expects the julia executable in the same folder as on the master computer (remember: workers are independent Julia processes). It will also try to `cd` to the same folder.\n",
    "\n",
    "In my case this would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pwd() = \"/Users/crstnbr/repos/JuliaNRW21/Day3\"\n",
      "Sys.BINDIR = \"/Applications/Julia-1.5.app/Contents/Resources/julia/bin\"\n"
     ]
    }
   ],
   "source": [
    "@show pwd();\n",
    "@show Sys.BINDIR;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both folders don't exist in my thp account (those are linux machines!), so I'll have to tell Julia to use different paths.\n",
    "\n",
    "Also, as per thp cluster guidelines one **(!) must (!) run computations on other thp computer with `nice -19` priority setting**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating `nice -19` workers and specifying directories "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from `?addprocs`, `addprocs` takes a bunch of keyword arguments, two of which are of particular importance.\n",
    "\n",
    "* `dir`: working directory of the worker process\n",
    "* `exename`: path to julia executable (potentially augmented with pre-commands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(exename = `\u001b[4mnice\u001b[24m \u001b[4m-19\u001b[24m \u001b[4m/home/bauer/bin/julia-1.5.3/bin/julia\u001b[24m \u001b[4m--project=/home/bauer/JuliaNRW21\u001b[24m`, dir = \"/home/bauer\")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = (exename=`nice -19 /home/bauer/bin/julia-1.5.3/bin/julia --project=/home/bauer/JuliaNRW21`, dir=\"/home/bauer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Int64,1}:\n",
       " 52\n",
       " 53\n",
       " 54\n",
       " 55"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs([(\"l93\", :auto)]; params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhcp-97-62.guest.uni-koeln.de\n",
      "      From worker 52:\tl93.thp.uni-koeln.de\n",
      "      From worker 53:\tl93.thp.uni-koeln.de\n",
      "      From worker 55:\tl93.thp.uni-koeln.de\n",
      "      From worker 54:\tl93.thp.uni-koeln.de\n"
     ]
    }
   ],
   "source": [
    "@everywhere println(gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Task (done) @0x00000001cbed1210"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's get some resources :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Tuple{String,Symbol},1}:\n",
       " (\"l93\", :auto)\n",
       " (\"l94\", :auto)\n",
       " (\"l96\", :auto)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machines = [\"l93\", \"l94\", \"l96\"];\n",
    "\n",
    "procs_per_machine = :auto; # :auto for n = # cpus\n",
    "\n",
    "jobs = [(m,procs_per_machine) for m in machines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12-element Array{Int64,1}:\n",
       " 56\n",
       " 57\n",
       " 58\n",
       " 59\n",
       " 60\n",
       " 61\n",
       " 62\n",
       " 63\n",
       " 64\n",
       " 65\n",
       " 66\n",
       " 67"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addprocs(jobs; params...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dhcp-97-62.guest.uni-koeln.de\n",
      "      From worker 57:\tl96.thp.uni-koeln.de\n",
      "      From worker 56:\tl94.thp.uni-koeln.de\n",
      "      From worker 58:\tl93.thp.uni-koeln.de\n",
      "      From worker 64:\tl96.thp.uni-koeln.de\n",
      "      From worker 62:\tl96.thp.uni-koeln.de\n",
      "      From worker 63:\tl96.thp.uni-koeln.de\n",
      "      From worker 65:\tl93.thp.uni-koeln.de\n",
      "      From worker 66:\tl93.thp.uni-koeln.de\n",
      "      From worker 67:\tl93.thp.uni-koeln.de\n",
      "      From worker 60:\tl94.thp.uni-koeln.de\n",
      "      From worker 61:\tl94.thp.uni-koeln.de\n",
      "      From worker 59:\tl94.thp.uni-koeln.de\n"
     ]
    }
   ],
   "source": [
    "@everywhere println(gethostname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.124102 seconds (872 allocations: 564.078 KiB)\n"
     ]
    }
   ],
   "source": [
    "@everywhere using LinearAlgebra\n",
    "\n",
    "@time x = pmap(svdvals, M);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed arrays (`DArray`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github: https://github.com/JuliaParallel/DistributedArrays.jl\n",
    "\n",
    "In a `DArray`, each process has local access to just a chunk of the data, and no two processes share the same chunk. Processes can be on different hosts.\n",
    "\n",
    "Distributed arrays are for example useful if\n",
    "\n",
    "* Expensive calculations should be performed in parallel on parts of the array on different hosts.\n",
    "* The data doesn't fit into the local machines memory (Loading big files in parallel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere using DistributedArrays, LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float32,1}:\n",
       " 1.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Float32[1f0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = Matrix{Float64}[rand(200,200) for i = 1:10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element DArray{Array{Float64,2},1,Array{Array{Float64,2},1}}:\n",
       " [0.01337893934171519 0.6383007772179348 … 0.9232854449134178 0.7786397015498232; 0.6764648985695592 0.8710713739835705 … 0.04302952137443894 0.9782183659320283; … ; 0.8387803569734145 0.04411367191271176 … 0.8708642373867417 0.8679096749147428; 0.6996509362923005 0.1457128149463085 … 0.4755287793092535 0.45512014913277477]\n",
       " [0.06945623421373548 0.21937443627135367 … 0.9746225858104136 0.4570707965014875; 0.5851725326541926 0.8075180112611648 … 0.9639791125237505 0.2178558665534891; … ; 0.6509885709870751 0.07275966900776143 … 0.5602675325797106 0.7930562356386581; 0.6878500258697111 0.5047204298065844 … 0.5508621127674576 0.39881015704265077]\n",
       " [0.5351228300582809 0.008724943627760329 … 0.17344482462123367 0.269940106838773; 0.34555826049386584 0.25697734587080623 … 0.3818029749373306 0.6759711328326057; … ; 0.03825981846103388 0.9717308570602656 … 0.7910976313466915 0.35621129530871776; 0.6480115519679497 0.41207530620993027 … 0.2024374136703897 0.26527847167849283]\n",
       " [0.30609548221390304 0.7438829314945865 … 0.19459903585678417 0.4351112481652235; 0.24588286508260082 0.6085922442497893 … 0.9525267925084189 0.7254435761427551; … ; 0.3997613633717283 0.9346765683127314 … 0.4768414036256663 0.20745358028273908; 0.3590748085149025 0.4999055143929094 … 0.2930478820497462 0.011051474314244913]\n",
       " [0.9778999115138336 0.1995977731017471 … 0.4695899467209512 0.811649435183827; 0.034940388242685305 0.8595884037471193 … 0.29629122142260034 0.8490011351003384; … ; 0.3256164269712152 0.8119333863096958 … 0.26425935959545366 0.663786451465662; 0.6043139808747029 0.9596189577871865 … 0.05643797428235375 0.046688744004633964]\n",
       " [0.5074417396552839 0.6653458021570862 … 0.37641151423825736 0.6316537167964111; 0.5231056058179311 0.8264055831286818 … 0.5922052590482083 0.4820166309327387; … ; 0.12013469809179234 0.4584824954412412 … 0.46456926801468756 0.01485434165343924; 0.24835706335631924 0.12285945223038897 … 0.1969138941119808 0.8576685398799315]\n",
       " [0.2525030835881781 0.43847120893833824 … 0.038949478190396514 0.9581426960260149; 0.5784269511425804 0.9084479160592704 … 0.9930838121383527 0.3409298611244955; … ; 0.1617661254532219 0.35863023469205624 … 0.8943542930002788 0.021172210320969498; 0.5299303110212548 0.02869431412639889 … 0.7185576565942888 0.5246059597926296]\n",
       " [0.590549097021354 0.24880870719484216 … 0.9245632836443198 0.9617851761102272; 0.821081866519737 0.45453818647671373 … 0.16469686391295468 0.5140337803668447; … ; 0.15595071389933746 0.9196688173174443 … 0.6880169948856647 0.8437936494940923; 0.04603731533808486 0.42520659486206847 … 0.17685404749115752 0.3491663713599005]\n",
       " [0.9964448280536347 0.3551770849251994 … 0.4266203927556973 0.20284278224923136; 0.8989710708791523 0.11827187400391592 … 0.9368801403230171 0.9911150449891277; … ; 0.15248335995829998 0.14111012642659015 … 0.9109552489206156 0.9545998447497812; 0.6009713064594351 0.027805594238516473 … 0.6501929004492872 0.30463028041374085]\n",
       " [0.24186743474519545 0.281487269504924 … 0.7566195311609389 0.7853376300974915; 0.3393436912568799 0.5957185315195688 … 0.593874723434864 0.8317228375511223; … ; 0.49151532723945435 0.6773908687464034 … 0.8631796874031612 0.7697819907867485; 0.3957360582510596 0.8381585625980588 … 0.0756839918556571 0.8956102612255061]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = distribute(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which workers hold parts of D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Int64,1}:\n",
       " 56\n",
       " 57\n",
       " 58\n",
       " 59\n",
       " 60\n",
       " 61\n",
       " 62\n",
       " 63\n",
       " 64\n",
       " 65"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "procs(D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which parts do they hold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Float64,2}[]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localpart(D) # the master doesn't hold anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.01337893934171519 0.6383007772179348 … 0.9232854449134178 0.7786397015498232; 0.6764648985695592 0.8710713739835705 … 0.04302952137443894 0.9782183659320283; … ; 0.8387803569734145 0.04411367191271176 … 0.8708642373867417 0.8679096749147428; 0.6996509362923005 0.1457128149463085 … 0.4755287793092535 0.45512014913277477]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1:1,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.06945623421373548 0.21937443627135367 … 0.9746225858104136 0.4570707965014875; 0.5851725326541926 0.8075180112611648 … 0.9639791125237505 0.2178558665534891; … ; 0.6509885709870751 0.07275966900776143 … 0.5602675325797106 0.7930562356386581; 0.6878500258697111 0.5047204298065844 … 0.5508621127674576 0.39881015704265077]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2:2,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.5351228300582809 0.008724943627760329 … 0.17344482462123367 0.269940106838773; 0.34555826049386584 0.25697734587080623 … 0.3818029749373306 0.6759711328326057; … ; 0.03825981846103388 0.9717308570602656 … 0.7910976313466915 0.35621129530871776; 0.6480115519679497 0.41207530620993027 … 0.2024374136703897 0.26527847167849283]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(3:3,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.30609548221390304 0.7438829314945865 … 0.19459903585678417 0.4351112481652235; 0.24588286508260082 0.6085922442497893 … 0.9525267925084189 0.7254435761427551; … ; 0.3997613633717283 0.9346765683127314 … 0.4768414036256663 0.20745358028273908; 0.3590748085149025 0.4999055143929094 … 0.2930478820497462 0.011051474314244913]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(4:4,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.9778999115138336 0.1995977731017471 … 0.4695899467209512 0.811649435183827; 0.034940388242685305 0.8595884037471193 … 0.29629122142260034 0.8490011351003384; … ; 0.3256164269712152 0.8119333863096958 … 0.26425935959545366 0.663786451465662; 0.6043139808747029 0.9596189577871865 … 0.05643797428235375 0.046688744004633964]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5:5,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.5074417396552839 0.6653458021570862 … 0.37641151423825736 0.6316537167964111; 0.5231056058179311 0.8264055831286818 … 0.5922052590482083 0.4820166309327387; … ; 0.12013469809179234 0.4584824954412412 … 0.46456926801468756 0.01485434165343924; 0.24835706335631924 0.12285945223038897 … 0.1969138941119808 0.8576685398799315]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(6:6,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.2525030835881781 0.43847120893833824 … 0.038949478190396514 0.9581426960260149; 0.5784269511425804 0.9084479160592704 … 0.9930838121383527 0.3409298611244955; … ; 0.1617661254532219 0.35863023469205624 … 0.8943542930002788 0.021172210320969498; 0.5299303110212548 0.02869431412639889 … 0.7185576565942888 0.5246059597926296]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(7:7,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.590549097021354 0.24880870719484216 … 0.9245632836443198 0.9617851761102272; 0.821081866519737 0.45453818647671373 … 0.16469686391295468 0.5140337803668447; … ; 0.15595071389933746 0.9196688173174443 … 0.6880169948856647 0.8437936494940923; 0.04603731533808486 0.42520659486206847 … 0.17685404749115752 0.3491663713599005]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8:8,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.9964448280536347 0.3551770849251994 … 0.4266203927556973 0.20284278224923136; 0.8989710708791523 0.11827187400391592 … 0.9368801403230171 0.9911150449891277; … ; 0.15248335995829998 0.14111012642659015 … 0.9109552489206156 0.9545998447497812; 0.6009713064594351 0.027805594238516473 … 0.6501929004492872 0.30463028041374085]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9:9,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1-element Array{Array{Float64,2},1}:\n",
       " [0.24186743474519545 0.281487269504924 … 0.7566195311609389 0.7853376300974915; 0.3393436912568799 0.5957185315195688 … 0.593874723434864 0.8317228375511223; … ; 0.49151532723945435 0.6773908687464034 … 0.8631796874031612 0.7697819907867485; 0.3957360582510596 0.8381585625980588 … 0.0756839918556571 0.8956102612255061]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(10:10,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array{Float64,2}[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1:0,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Array{Float64,2}[]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1:0,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Which parts do they hold?\n",
    "for p in workers()\n",
    "    display(@fetchfrom p localpart(D))\n",
    "    display(@fetchfrom p DistributedArrays.localindices(D)) # DistributedArrays. necessary because of SharedArrays above\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.062303 seconds (82 allocations: 4.219 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time Msquared = map(svdvals, M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.009922 seconds (1.52 k allocations: 82.156 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time Dsquared = map(svdvals, D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.042258 seconds (825 allocations: 50.781 KiB)\n"
     ]
    }
   ],
   "source": [
    "@time Psquared = pmap(svdvals, M);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Msquared ≈ Dsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dsquared ≈ Psquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Array{Array{Float64,2},1}:\n",
       " [0.01337893934171519 0.6383007772179348 … 0.9232854449134178 0.7786397015498232; 0.6764648985695592 0.8710713739835705 … 0.04302952137443894 0.9782183659320283; … ; 0.8387803569734145 0.04411367191271176 … 0.8708642373867417 0.8679096749147428; 0.6996509362923005 0.1457128149463085 … 0.4755287793092535 0.45512014913277477]\n",
       " [0.06945623421373548 0.21937443627135367 … 0.9746225858104136 0.4570707965014875; 0.5851725326541926 0.8075180112611648 … 0.9639791125237505 0.2178558665534891; … ; 0.6509885709870751 0.07275966900776143 … 0.5602675325797106 0.7930562356386581; 0.6878500258697111 0.5047204298065844 … 0.5508621127674576 0.39881015704265077]\n",
       " [0.5351228300582809 0.008724943627760329 … 0.17344482462123367 0.269940106838773; 0.34555826049386584 0.25697734587080623 … 0.3818029749373306 0.6759711328326057; … ; 0.03825981846103388 0.9717308570602656 … 0.7910976313466915 0.35621129530871776; 0.6480115519679497 0.41207530620993027 … 0.2024374136703897 0.26527847167849283]\n",
       " [0.30609548221390304 0.7438829314945865 … 0.19459903585678417 0.4351112481652235; 0.24588286508260082 0.6085922442497893 … 0.9525267925084189 0.7254435761427551; … ; 0.3997613633717283 0.9346765683127314 … 0.4768414036256663 0.20745358028273908; 0.3590748085149025 0.4999055143929094 … 0.2930478820497462 0.011051474314244913]\n",
       " [0.9778999115138336 0.1995977731017471 … 0.4695899467209512 0.811649435183827; 0.034940388242685305 0.8595884037471193 … 0.29629122142260034 0.8490011351003384; … ; 0.3256164269712152 0.8119333863096958 … 0.26425935959545366 0.663786451465662; 0.6043139808747029 0.9596189577871865 … 0.05643797428235375 0.046688744004633964]\n",
       " [0.5074417396552839 0.6653458021570862 … 0.37641151423825736 0.6316537167964111; 0.5231056058179311 0.8264055831286818 … 0.5922052590482083 0.4820166309327387; … ; 0.12013469809179234 0.4584824954412412 … 0.46456926801468756 0.01485434165343924; 0.24835706335631924 0.12285945223038897 … 0.1969138941119808 0.8576685398799315]\n",
       " [0.2525030835881781 0.43847120893833824 … 0.038949478190396514 0.9581426960260149; 0.5784269511425804 0.9084479160592704 … 0.9930838121383527 0.3409298611244955; … ; 0.1617661254532219 0.35863023469205624 … 0.8943542930002788 0.021172210320969498; 0.5299303110212548 0.02869431412639889 … 0.7185576565942888 0.5246059597926296]\n",
       " [0.590549097021354 0.24880870719484216 … 0.9245632836443198 0.9617851761102272; 0.821081866519737 0.45453818647671373 … 0.16469686391295468 0.5140337803668447; … ; 0.15595071389933746 0.9196688173174443 … 0.6880169948856647 0.8437936494940923; 0.04603731533808486 0.42520659486206847 … 0.17685404749115752 0.3491663713599005]\n",
       " [0.9964448280536347 0.3551770849251994 … 0.4266203927556973 0.20284278224923136; 0.8989710708791523 0.11827187400391592 … 0.9368801403230171 0.9911150449891277; … ; 0.15248335995829998 0.14111012642659015 … 0.9109552489206156 0.9545998447497812; 0.6009713064594351 0.027805594238516473 … 0.6501929004492872 0.30463028041374085]\n",
       " [0.24186743474519545 0.281487269504924 … 0.7566195311609389 0.7853376300974915; 0.3393436912568799 0.5957185315195688 … 0.593874723434864 0.8317228375511223; … ; 0.49151532723945435 0.6773908687464034 … 0.8631796874031612 0.7697819907867485; 0.3957360582510596 0.8381585625980588 … 0.0756839918556571 0.8956102612255061]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But remember, for small operations the data movement can (and will) exceed the benefit of parallelizing the computation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.072825 seconds (102.28 k allocations: 5.448 MiB)\n",
      "  0.261873 seconds (322.80 k allocations: 16.455 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time map(sum, M);\n",
    "@time map(sum, D);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: rmprocs: process 1 not removed\n",
      "└ @ Distributed /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/Distributed/src/cluster.jl:1030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Task (done) @0x000000012fb0fa90"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stop worker processes!\n",
    "rmprocs(workers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@everywhere begin\n",
    "    using LinearAlgebra \n",
    "\n",
    "    function mycalc()\n",
    "        blablabla\n",
    "    end\n",
    "end\n",
    "\n",
    "pmap(svdvals, D)"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
